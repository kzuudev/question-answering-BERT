{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5qPjJmHSGryK",
        "aJIx9GC8IbTw",
        "E8zdKOR1RAB0",
        "dWy6J1HBJVYc",
        "mmLJy4pAOHTK",
        "Xpl6mXprDVDe",
        "QWTDiCCgJZVD"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d726fb334d6b4fa5ba453b65b58d9195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_369cc86d64334ed28e8766ae56846d1b",
              "IPY_MODEL_20a7fa80ccb04102b7a52d37525f61e5",
              "IPY_MODEL_6b28a4b010664cb09b930e44d155f2bc"
            ],
            "layout": "IPY_MODEL_83fe8089f6a64526807a8f4bdaba80bc"
          }
        },
        "369cc86d64334ed28e8766ae56846d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c9e9c7f254412193bb13199d8eda87",
            "placeholder": "​",
            "style": "IPY_MODEL_38b4bd604d9a49f79d49508a4a2a02ad",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "20a7fa80ccb04102b7a52d37525f61e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b719ccc75ed45dcb53bf2add14bb560",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53f3e17cbd044196864d143d54225aaa",
            "value": 48
          }
        },
        "6b28a4b010664cb09b930e44d155f2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e20f664716453c8cbffd16006c2a04",
            "placeholder": "​",
            "style": "IPY_MODEL_bbd91e8613454e96ae1a837b34b74903",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.88kB/s]"
          }
        },
        "83fe8089f6a64526807a8f4bdaba80bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c9e9c7f254412193bb13199d8eda87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b4bd604d9a49f79d49508a4a2a02ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b719ccc75ed45dcb53bf2add14bb560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f3e17cbd044196864d143d54225aaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14e20f664716453c8cbffd16006c2a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbd91e8613454e96ae1a837b34b74903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c807d8cae97544ed99b9d1b4bfbd0ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_758cc92e497c4096a6469a8dabb50c9a",
              "IPY_MODEL_2f14fd14d7cd43a29030383240718ea6",
              "IPY_MODEL_8ab6860984cb495085cdd53568a29e1b"
            ],
            "layout": "IPY_MODEL_7d34767b0e584cf3ac11d4b97b64f158"
          }
        },
        "758cc92e497c4096a6469a8dabb50c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9ad01ca1e3b4902984e3f8e9f7681ad",
            "placeholder": "​",
            "style": "IPY_MODEL_9fe5a350aaf34ced84c44505f7c152cf",
            "value": "vocab.txt: 100%"
          }
        },
        "2f14fd14d7cd43a29030383240718ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50f4939e294b454bba83887a2d11b6e8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a20ad4c7d0e4fe48580d697d492e51f",
            "value": 231508
          }
        },
        "8ab6860984cb495085cdd53568a29e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ceb1c19fc65405399192c7fd45a7165",
            "placeholder": "​",
            "style": "IPY_MODEL_5d6d1d88b4bd4a4da36096b8f278254f",
            "value": " 232k/232k [00:00&lt;00:00, 1.75MB/s]"
          }
        },
        "7d34767b0e584cf3ac11d4b97b64f158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9ad01ca1e3b4902984e3f8e9f7681ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fe5a350aaf34ced84c44505f7c152cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50f4939e294b454bba83887a2d11b6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a20ad4c7d0e4fe48580d697d492e51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ceb1c19fc65405399192c7fd45a7165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6d1d88b4bd4a4da36096b8f278254f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "862ec1c83e7a4680972a7f8d6952e3c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_728eb1876ea1412caa27aea88fe7b891",
              "IPY_MODEL_24da598d5769477084ab465baf158612",
              "IPY_MODEL_77de08921d5444d8adfa3eee3482eee0"
            ],
            "layout": "IPY_MODEL_a48a2e2a3d114d51924ce5cc949bbe9e"
          }
        },
        "728eb1876ea1412caa27aea88fe7b891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a460acca5b574fe38357096b858689ef",
            "placeholder": "​",
            "style": "IPY_MODEL_9d0374b9a0fd45cd83dc9b6b752663ea",
            "value": "tokenizer.json: 100%"
          }
        },
        "24da598d5769477084ab465baf158612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34a5b828761449bcb9d27c63d98cf10b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f94bc6f5cd645509aa46d90b3838408",
            "value": 466062
          }
        },
        "77de08921d5444d8adfa3eee3482eee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d16a10e5ac0341a4ab8b0fdaffbd9618",
            "placeholder": "​",
            "style": "IPY_MODEL_9bc6d8261aa84d329054e21c89c3d442",
            "value": " 466k/466k [00:00&lt;00:00, 25.5MB/s]"
          }
        },
        "a48a2e2a3d114d51924ce5cc949bbe9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a460acca5b574fe38357096b858689ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d0374b9a0fd45cd83dc9b6b752663ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34a5b828761449bcb9d27c63d98cf10b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f94bc6f5cd645509aa46d90b3838408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d16a10e5ac0341a4ab8b0fdaffbd9618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc6d8261aa84d329054e21c89c3d442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04d1b020c4c84c1a9a4f8e41db05153a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e11079d733740cd99762b37c65b23a8",
              "IPY_MODEL_34045deb025b4acbbebfb2018e12fc28",
              "IPY_MODEL_f7235646365b4ba9b2dce7df4056cb48"
            ],
            "layout": "IPY_MODEL_8307183a1e6f443c9a1591acf0cd4c4a"
          }
        },
        "9e11079d733740cd99762b37c65b23a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_965ae0d8593540f9bcd6dc61d67f7eba",
            "placeholder": "​",
            "style": "IPY_MODEL_25d5268dc436459f9c3fb7f907ce46e5",
            "value": "config.json: 100%"
          }
        },
        "34045deb025b4acbbebfb2018e12fc28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d29460bcf3c74ce8a05539e18d240a32",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f67905a470843b0bc3a2e6b10958647",
            "value": 570
          }
        },
        "f7235646365b4ba9b2dce7df4056cb48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d6dcf92cad54cf7b79d60a6a8172d7d",
            "placeholder": "​",
            "style": "IPY_MODEL_6d25f2f991b9427aa04e153ef028336b",
            "value": " 570/570 [00:00&lt;00:00, 66.4kB/s]"
          }
        },
        "8307183a1e6f443c9a1591acf0cd4c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965ae0d8593540f9bcd6dc61d67f7eba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d5268dc436459f9c3fb7f907ce46e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d29460bcf3c74ce8a05539e18d240a32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f67905a470843b0bc3a2e6b10958647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d6dcf92cad54cf7b79d60a6a8172d7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d25f2f991b9427aa04e153ef028336b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa48491dfc454c2680889a5afabe1633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08a31cf6b5f04685b72eeb8c26290121",
              "IPY_MODEL_1076ec2ba8374905b3518f3eef2424bf",
              "IPY_MODEL_21b51dfa938b464caae12008d8d75f37"
            ],
            "layout": "IPY_MODEL_409701c9f5e14e6388d8c07d9d157b1d"
          }
        },
        "08a31cf6b5f04685b72eeb8c26290121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea7f8109e9c648b8b0b0e9e225079e3b",
            "placeholder": "​",
            "style": "IPY_MODEL_6ec5589c180e4a82b02a5b84b67de061",
            "value": "model.safetensors: 100%"
          }
        },
        "1076ec2ba8374905b3518f3eef2424bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675108f3e3b748258833fbd9775652f6",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0066e6504b54aa1970b7178be2befc0",
            "value": 440449768
          }
        },
        "21b51dfa938b464caae12008d8d75f37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4928e9970314b57bbb44daf350ac96d",
            "placeholder": "​",
            "style": "IPY_MODEL_fcd0238d22b44113a46be788a7273f38",
            "value": " 440M/440M [00:04&lt;00:00, 115MB/s]"
          }
        },
        "409701c9f5e14e6388d8c07d9d157b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea7f8109e9c648b8b0b0e9e225079e3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec5589c180e4a82b02a5b84b67de061": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675108f3e3b748258833fbd9775652f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0066e6504b54aa1970b7178be2befc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b4928e9970314b57bbb44daf350ac96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcd0238d22b44113a46be788a7273f38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11a46f1ad95741689bd18957df1b4c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8e7aad27a814676bd00e0582fcf0fb2",
              "IPY_MODEL_9100894f26974b389f97bcbecb992bdf",
              "IPY_MODEL_9f096961a0e64cc1b46411673719982b"
            ],
            "layout": "IPY_MODEL_940d5413ab5246bf88d76902e6882225"
          }
        },
        "d8e7aad27a814676bd00e0582fcf0fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f2575b7c9eb4b4485c5ff793fcf459e",
            "placeholder": "​",
            "style": "IPY_MODEL_4f4f457f8eaa403f84d8c67f8a5a65d7",
            "value": "Map: 100%"
          }
        },
        "9100894f26974b389f97bcbecb992bdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60863e4a669848069d9b7a3069a70b96",
            "max": 568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf95687d9ef248ec89ef5b29d03c4f0b",
            "value": 568
          }
        },
        "9f096961a0e64cc1b46411673719982b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66a7ecc2dedb457b9c8753bff12ea524",
            "placeholder": "​",
            "style": "IPY_MODEL_e062d732190a49bb8353450ac092135a",
            "value": " 568/568 [00:00&lt;00:00, 5181.86 examples/s]"
          }
        },
        "940d5413ab5246bf88d76902e6882225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f2575b7c9eb4b4485c5ff793fcf459e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4f457f8eaa403f84d8c67f8a5a65d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60863e4a669848069d9b7a3069a70b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf95687d9ef248ec89ef5b29d03c4f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66a7ecc2dedb457b9c8753bff12ea524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e062d732190a49bb8353450ac092135a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c48862dfdb04fa9894c33b46b1a8cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05b150ac1384368b445ebcc8b4424d3",
              "IPY_MODEL_2527979a987c4a8dbb85f7e3b45d232f",
              "IPY_MODEL_846131953c10478c81df182d4336f4b6"
            ],
            "layout": "IPY_MODEL_fe7d84c33302455d95fce0e99e27a541"
          }
        },
        "e05b150ac1384368b445ebcc8b4424d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e3c095a734426ca7a5046b6f165584",
            "placeholder": "​",
            "style": "IPY_MODEL_1a6c2bc8b37249098253b7184be1c15b",
            "value": "Map: 100%"
          }
        },
        "2527979a987c4a8dbb85f7e3b45d232f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_996d4ec0b5594d43b4e9ac57823be786",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_965fb6eb21f545a3bd8a73c442566c92",
            "value": 142
          }
        },
        "846131953c10478c81df182d4336f4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f6cf3ca4ef466090407d6b55b5b25d",
            "placeholder": "​",
            "style": "IPY_MODEL_b00d2a60904b4b71b5a3f61bc5067fef",
            "value": " 142/142 [00:00&lt;00:00, 3085.58 examples/s]"
          }
        },
        "fe7d84c33302455d95fce0e99e27a541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e3c095a734426ca7a5046b6f165584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a6c2bc8b37249098253b7184be1c15b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "996d4ec0b5594d43b4e9ac57823be786": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965fb6eb21f545a3bd8a73c442566c92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30f6cf3ca4ef466090407d6b55b5b25d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00d2a60904b4b71b5a3f61bc5067fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6732ca22ada349eeba8b9e28dec71472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4d12378ec03454897bea501324c5ce5",
              "IPY_MODEL_92094de318f240b2af7e94b1b7371f25",
              "IPY_MODEL_09de01b17cce4b00b358728dc50de0f9"
            ],
            "layout": "IPY_MODEL_c2144e49b51a43b29b58d23f33f20108"
          }
        },
        "a4d12378ec03454897bea501324c5ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22bb888d8a3c4de29d40b4a631c41f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_5cfa40e4aa524597b0212ca8f548f0b6",
            "value": "Map: 100%"
          }
        },
        "92094de318f240b2af7e94b1b7371f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f09cef3369474f47b5668d2a9971c55c",
            "max": 568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1fc79b77049249d6a7985836e7d7aa4a",
            "value": 568
          }
        },
        "09de01b17cce4b00b358728dc50de0f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a36158bcff014777bff9da97060ed83f",
            "placeholder": "​",
            "style": "IPY_MODEL_f2956b41f9744bdf86aa9683dbb62c20",
            "value": " 568/568 [00:00&lt;00:00, 790.53 examples/s]"
          }
        },
        "c2144e49b51a43b29b58d23f33f20108": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22bb888d8a3c4de29d40b4a631c41f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cfa40e4aa524597b0212ca8f548f0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f09cef3369474f47b5668d2a9971c55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fc79b77049249d6a7985836e7d7aa4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a36158bcff014777bff9da97060ed83f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2956b41f9744bdf86aa9683dbb62c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d7e6965158f48c3b34336652dfd334f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_241fea7f7ffb4a84912cf482fc61fe18",
              "IPY_MODEL_543d5797711344128747ec703ea237fa",
              "IPY_MODEL_c0c1a2af97264d828ac1f03fb7d78dba"
            ],
            "layout": "IPY_MODEL_f4ff2356da4c4ba18610bf9d98920eef"
          }
        },
        "241fea7f7ffb4a84912cf482fc61fe18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a763d6fec2046f69f333cbe7d23f9e1",
            "placeholder": "​",
            "style": "IPY_MODEL_4db6043f91a24f84bc9ce7f1f701ea17",
            "value": "Map: 100%"
          }
        },
        "543d5797711344128747ec703ea237fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e2692b156844a6d8a6ddb81315f1f03",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33ff3de3429242cdaf836bdfe3d4b857",
            "value": 142
          }
        },
        "c0c1a2af97264d828ac1f03fb7d78dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b74f0576640c4d16ab6c33595b6412e4",
            "placeholder": "​",
            "style": "IPY_MODEL_4428134b09e34f26b7c2c2c75bf5f9d1",
            "value": " 142/142 [00:00&lt;00:00, 702.52 examples/s]"
          }
        },
        "f4ff2356da4c4ba18610bf9d98920eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a763d6fec2046f69f333cbe7d23f9e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4db6043f91a24f84bc9ce7f1f701ea17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e2692b156844a6d8a6ddb81315f1f03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33ff3de3429242cdaf836bdfe3d4b857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b74f0576640c4d16ab6c33595b6412e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4428134b09e34f26b7c2c2c75bf5f9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Setup and Data Preparation**"
      ],
      "metadata": {
        "id": "5qPjJmHSGryK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code block loads a CSV dataset from Google Drive (in this case `(\"/content/drive/My Drive/Data Collection (ITE Elective Course Lesson)/Dataset/Webscraped data - ITE Elective 3 - Sheet1.csv\")`, then processes it into a suitable format for `transformers` libraries. It also checks GPU availability to enable efficient computation.\n",
        "\n",
        "**Input**\n",
        "\n",
        "The input in this code block is the CSV file from Google Drive containing text data for model training\n",
        "\n",
        "**Output**\n",
        "\n",
        "The output in this code block is the confirmation message about GPU or CPU usage. Two datasets printed to the console: training data `(train_data)` and evaluation data `(eval_data)`.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "\n",
        "\n",
        "    drive.mount('/content/drive/', force_remount=True) mounts Google Drive to access external files.\n",
        "\n",
        "    pd.read_csv(path) loads the dataset into a pandas DataFrame.\n",
        "\n",
        "    torch.cuda.is_available() checks whether a GPU is accessible.\n",
        "\n",
        "    Dataset.from_pandas(df) converts a pandas DataFrame into a Hugging Face Dataset object.\n",
        "\n",
        "    dataset.train_test_split(test_size=0.2, seed=42) splits the dataset into 80% training and 20% evaluation data.\n",
        "\n",
        "    torch.device(\"cuda\" or \"cpu\") specifies the computation device for model training.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "Mounted at /content/drive/\n",
        "Using GPU: Tesla T4\n",
        "\n",
        "--- Loading and Preprocessing Data ---\n",
        "Dataset({\n",
        "    features: ['column1', 'column2', 'column3'],\n",
        "    num_rows: 400\n",
        "})\n",
        "Dataset({\n",
        "    features: ['column1', 'column2', 'column3'],\n",
        "    num_rows: 100\n",
        "})\n",
        "\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "Based on my understanding, the code demonstrates a typical preprocessing workflow for NLP model training using Hugging Face. It ensures GPU acceleration if available, which significantly speeds up training. Moreover, converting the dataset into the Hugging Face format allows easy integration with a `Trainer` later on."
      ],
      "metadata": {
        "id": "LDkbIboypqOS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BOQpViEWvJcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6beec11f-0412-4aa1-e3f0-b8fcd970cb62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Cleaned dataset shape: (710, 7)\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "--- Loading and Preprocessing Data ---\n",
            "Dataset({\n",
            "    features: ['ID', 'Title', 'Context', 'Question', 'Answer', 'Unnamed: 5', 'Unnamed: 6', '__index_level_0__'],\n",
            "    num_rows: 568\n",
            "})\n",
            "Dataset({\n",
            "    features: ['ID', 'Title', 'Context', 'Question', 'Answer', 'Unnamed: 5', 'Unnamed: 6', '__index_level_0__'],\n",
            "    num_rows: 142\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import time\n",
        "import random\n",
        "import itertools\n",
        "from datasets import Dataset\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from google.colab import drive\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers.data.data_collator import default_data_collator # Import default_data_collator\n",
        "\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "df = pd.read_excel(\"/content/drive/My Drive/Data Collection (ITE Elective Course Lesson)/Dataset/Webscraped data_Modules_Question and Answering.xlsx\")\n",
        "\n",
        "\n",
        "df.dropna (subset=['Title', 'Context', 'Question', 'Answer'], inplace=True)\n",
        "\n",
        "\n",
        "for col in ['Context', 'Question', 'Answer', 'Title']:\n",
        "  df[col] = df[col].astype(str)\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<[^>]+>', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^A-Za-z0-9.,;:?!\\'\"()\\-\\s]', '', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "df['Context'] = df['Context'].apply(clean_text)\n",
        "df['Question'] = df['Question'].apply(clean_text)\n",
        "df['Answer'] = df['Answer'].apply(clean_text)\n",
        "\n",
        "print(f\"Cleaned dataset shape: {df.shape}\")\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")\n",
        "\n",
        "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
        "\n",
        "\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_data = dataset[\"train\"]\n",
        "eval_data = dataset[\"test\"]\n",
        "\n",
        "print(train_data)\n",
        "print(eval_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bert-base-uncased**"
      ],
      "metadata": {
        "id": "aJIx9GC8IbTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code loads a pre-trained BERT model and tokenizer for question answering tasks, processes datasets by aligning answer positions within contexts, and tokenizes the data while mapping character-based answer spans to token spans suitable for model training. It also detects GPU availability to accelerate model training and inference.\n",
        "\n",
        "**Input**\n",
        "\n",
        "The input consists of datasets containing questions, contexts, and answers, which are prepared as train_data and eval_data before processing. These datasets include fields like \"Question,\" \"Context,\" \"Answer,\" and answer positions.\n",
        "\n",
        "**Output**\n",
        "\n",
        "The output includes tokenized datasets (tokenized_train and tokenized_eval) that are formatted for PyTorch training, with added start and end position labels for answers. Additionally, the script confirms the successful loading of the model and the availability of GPU acceleration, printing relevant messages.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "\n",
        "    Imports the necessary classes for tokenization and model loading.\n",
        "\n",
        "python\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    Loads a pre-trained BERT tokenizer and model based on bert-base-uncased.\n",
        "\n",
        "python\n",
        "def add_answer_positions(example):\n",
        "    ...\n",
        "    return example\n",
        "\n",
        "    Adds start and end answer positions within the context, matching answer text to context.\n",
        "\n",
        "python\n",
        "def tokenize_and_align(examples):\n",
        "    ...\n",
        "    return tokenized\n",
        "\n",
        "    Tokenizes question and context, aligns answer spans with token indices, and prepares data for model training.\n",
        "\n",
        "python\n",
        "train_data.map(add_answer_positions)\n",
        "eval_data.map(add_answer_positions)\n",
        "\n",
        "train_data.map(tokenize_and_align, batched=True)\n",
        "eval_data.map(tokenize_and_align, batched=True)\n",
        "\n",
        "    Applies position setting and tokenization functions on datasets.\n",
        "\n",
        "python\n",
        "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    Checks for GPU availability and assigns the device accordingly.\n",
        "\n",
        "python\n",
        "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "    Loads the model to the appropriate device for training or inference.\n",
        "\n",
        "Example Output\n",
        "\n",
        "text\n",
        "Loaded Pretrained QnA Model: bert-base-uncased\n",
        "🧩 Model loaded successfully for QnA: bert-base-uncased\n",
        "\n",
        "Comment and Observation\n",
        "\n",
        "This code exemplifies a typical NLP pipeline for question answering with BERT. It carefully maps answer spans from character-level positions within the context to token indices, which is essential for model training. Importantly, it checks for GPU availability to optimize performance, making it suitable for large datasets and neural network fine-tuning tasks. The structured approach ensures correct data alignment and efficient model loading, facilitating smooth integration into a training loop later on."
      ],
      "metadata": {
        "id": "D0pP3KAAQZbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(f\"\\n Loaded Pretrained QnA Model: {MODEL_NAME}\")\n",
        "\n",
        "\n",
        "def add_answer_positions(example):\n",
        "    context = example[\"Context\"]\n",
        "    answer = example[\"Answer\"]\n",
        "\n",
        "\n",
        "    context_lower = context.lower()\n",
        "    answer_lower = answer.lower()\n",
        "\n",
        "    answer_start = context_lower.find(answer_lower)\n",
        "    if answer_start == 0:\n",
        "\n",
        "        example[\"start_positions\"] = 0\n",
        "        example[\"end_positions\"] = 0\n",
        "    else:\n",
        "        answer_end = answer_start + len(answer)\n",
        "        example[\"start_positions\"] = answer_start\n",
        "        example[\"end_positions\"] = answer_end\n",
        "\n",
        "    return example\n",
        "\n",
        "\n",
        "def tokenize_and_align(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"Question\"],\n",
        "        examples[\"Context\"],\n",
        "        truncation=\"only_second\",\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
        "        sequence_ids = tokenized.sequence_ids(i)\n",
        "        context_start = sequence_ids.index(1)\n",
        "        context_end = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
        "\n",
        "        start_char = examples[\"start_positions\"][i]\n",
        "        end_char = examples[\"end_positions\"][i]\n",
        "\n",
        "\n",
        "        token_start_index = context_start\n",
        "        token_end_index = context_start\n",
        "\n",
        "\n",
        "        for idx in range(context_start, context_end + 1):\n",
        "            if offsets[idx][0] <= start_char < offsets[idx][1]:\n",
        "                token_start_index = idx\n",
        "            if offsets[idx][0] < end_char <= offsets[idx][1]:\n",
        "                token_end_index = idx\n",
        "                break\n",
        "\n",
        "        start_positions.append(token_start_index)\n",
        "        end_positions.append(token_end_index)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "    tokenized.pop(\"offset_mapping\")\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "\n",
        "train_data = train_data.map(add_answer_positions)\n",
        "eval_data = eval_data.map(add_answer_positions)\n",
        "\n",
        "\n",
        "tokenized_train = train_data.map(tokenize_and_align, batched=True)\n",
        "tokenized_eval = eval_data.map(tokenize_and_align, batched=True)\n",
        "\n",
        "tokenized_train.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
        "tokenized_eval.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "print(f\"\\n Model loaded successfully for QnA: {MODEL_NAME}\")"
      ],
      "metadata": {
        "id": "lkp9RR_6yOSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561,
          "referenced_widgets": [
            "d726fb334d6b4fa5ba453b65b58d9195",
            "369cc86d64334ed28e8766ae56846d1b",
            "20a7fa80ccb04102b7a52d37525f61e5",
            "6b28a4b010664cb09b930e44d155f2bc",
            "83fe8089f6a64526807a8f4bdaba80bc",
            "29c9e9c7f254412193bb13199d8eda87",
            "38b4bd604d9a49f79d49508a4a2a02ad",
            "9b719ccc75ed45dcb53bf2add14bb560",
            "53f3e17cbd044196864d143d54225aaa",
            "14e20f664716453c8cbffd16006c2a04",
            "bbd91e8613454e96ae1a837b34b74903",
            "c807d8cae97544ed99b9d1b4bfbd0ffe",
            "758cc92e497c4096a6469a8dabb50c9a",
            "2f14fd14d7cd43a29030383240718ea6",
            "8ab6860984cb495085cdd53568a29e1b",
            "7d34767b0e584cf3ac11d4b97b64f158",
            "a9ad01ca1e3b4902984e3f8e9f7681ad",
            "9fe5a350aaf34ced84c44505f7c152cf",
            "50f4939e294b454bba83887a2d11b6e8",
            "6a20ad4c7d0e4fe48580d697d492e51f",
            "7ceb1c19fc65405399192c7fd45a7165",
            "5d6d1d88b4bd4a4da36096b8f278254f",
            "862ec1c83e7a4680972a7f8d6952e3c4",
            "728eb1876ea1412caa27aea88fe7b891",
            "24da598d5769477084ab465baf158612",
            "77de08921d5444d8adfa3eee3482eee0",
            "a48a2e2a3d114d51924ce5cc949bbe9e",
            "a460acca5b574fe38357096b858689ef",
            "9d0374b9a0fd45cd83dc9b6b752663ea",
            "34a5b828761449bcb9d27c63d98cf10b",
            "2f94bc6f5cd645509aa46d90b3838408",
            "d16a10e5ac0341a4ab8b0fdaffbd9618",
            "9bc6d8261aa84d329054e21c89c3d442",
            "04d1b020c4c84c1a9a4f8e41db05153a",
            "9e11079d733740cd99762b37c65b23a8",
            "34045deb025b4acbbebfb2018e12fc28",
            "f7235646365b4ba9b2dce7df4056cb48",
            "8307183a1e6f443c9a1591acf0cd4c4a",
            "965ae0d8593540f9bcd6dc61d67f7eba",
            "25d5268dc436459f9c3fb7f907ce46e5",
            "d29460bcf3c74ce8a05539e18d240a32",
            "8f67905a470843b0bc3a2e6b10958647",
            "8d6dcf92cad54cf7b79d60a6a8172d7d",
            "6d25f2f991b9427aa04e153ef028336b",
            "fa48491dfc454c2680889a5afabe1633",
            "08a31cf6b5f04685b72eeb8c26290121",
            "1076ec2ba8374905b3518f3eef2424bf",
            "21b51dfa938b464caae12008d8d75f37",
            "409701c9f5e14e6388d8c07d9d157b1d",
            "ea7f8109e9c648b8b0b0e9e225079e3b",
            "6ec5589c180e4a82b02a5b84b67de061",
            "675108f3e3b748258833fbd9775652f6",
            "f0066e6504b54aa1970b7178be2befc0",
            "b4928e9970314b57bbb44daf350ac96d",
            "fcd0238d22b44113a46be788a7273f38",
            "11a46f1ad95741689bd18957df1b4c8d",
            "d8e7aad27a814676bd00e0582fcf0fb2",
            "9100894f26974b389f97bcbecb992bdf",
            "9f096961a0e64cc1b46411673719982b",
            "940d5413ab5246bf88d76902e6882225",
            "9f2575b7c9eb4b4485c5ff793fcf459e",
            "4f4f457f8eaa403f84d8c67f8a5a65d7",
            "60863e4a669848069d9b7a3069a70b96",
            "bf95687d9ef248ec89ef5b29d03c4f0b",
            "66a7ecc2dedb457b9c8753bff12ea524",
            "e062d732190a49bb8353450ac092135a",
            "2c48862dfdb04fa9894c33b46b1a8cdc",
            "e05b150ac1384368b445ebcc8b4424d3",
            "2527979a987c4a8dbb85f7e3b45d232f",
            "846131953c10478c81df182d4336f4b6",
            "fe7d84c33302455d95fce0e99e27a541",
            "d7e3c095a734426ca7a5046b6f165584",
            "1a6c2bc8b37249098253b7184be1c15b",
            "996d4ec0b5594d43b4e9ac57823be786",
            "965fb6eb21f545a3bd8a73c442566c92",
            "30f6cf3ca4ef466090407d6b55b5b25d",
            "b00d2a60904b4b71b5a3f61bc5067fef",
            "6732ca22ada349eeba8b9e28dec71472",
            "a4d12378ec03454897bea501324c5ce5",
            "92094de318f240b2af7e94b1b7371f25",
            "09de01b17cce4b00b358728dc50de0f9",
            "c2144e49b51a43b29b58d23f33f20108",
            "22bb888d8a3c4de29d40b4a631c41f5f",
            "5cfa40e4aa524597b0212ca8f548f0b6",
            "f09cef3369474f47b5668d2a9971c55c",
            "1fc79b77049249d6a7985836e7d7aa4a",
            "a36158bcff014777bff9da97060ed83f",
            "f2956b41f9744bdf86aa9683dbb62c20",
            "0d7e6965158f48c3b34336652dfd334f",
            "241fea7f7ffb4a84912cf482fc61fe18",
            "543d5797711344128747ec703ea237fa",
            "c0c1a2af97264d828ac1f03fb7d78dba",
            "f4ff2356da4c4ba18610bf9d98920eef",
            "2a763d6fec2046f69f333cbe7d23f9e1",
            "4db6043f91a24f84bc9ce7f1f701ea17",
            "8e2692b156844a6d8a6ddb81315f1f03",
            "33ff3de3429242cdaf836bdfe3d4b857",
            "b74f0576640c4d16ab6c33595b6412e4",
            "4428134b09e34f26b7c2c2c75bf5f9d1"
          ]
        },
        "outputId": "ef926b9f-897c-4bfb-b5a8-439032badce5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d726fb334d6b4fa5ba453b65b58d9195"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c807d8cae97544ed99b9d1b4bfbd0ffe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "862ec1c83e7a4680972a7f8d6952e3c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04d1b020c4c84c1a9a4f8e41db05153a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa48491dfc454c2680889a5afabe1633"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Loaded Pretrained QnA Model: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11a46f1ad95741689bd18957df1b4c8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/142 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c48862dfdb04fa9894c33b46b1a8cdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6732ca22ada349eeba8b9e28dec71472"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/142 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d7e6965158f48c3b34336652dfd334f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model loaded successfully for QnA: bert-base-uncased\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "orJ1vJMTKVzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **METRICS AND TRAINING SETUP**"
      ],
      "metadata": {
        "id": "PnJYq08SJOfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This command installs several important Python packages that are essential for working with transformer models and hyperparameter optimization:\n",
        "\n",
        "    transformers: Hugging Face's library for state-of-the-art transformer models like BERT, GPT, and more.\n",
        "\n",
        "    datasets: Hugging Face's library for easily accessing and managing datasets.\n",
        "\n",
        "    accelerate: A library to help scale PyTorch models across multiple GPUs or TPUs.\n",
        "\n",
        "    ray[tune]: Ray Tune is a scalable hyperparameter tuning library built on Ray.\n",
        "\n",
        "    optuna: A popular framework for automated hyperparameter optimization.\n",
        "\n",
        "The purpose of this code is to search results show that Optuna and Ray Tune can be integrated with the Transformers Trainer to perform hyperparameter searches efficiently. Installing these packages sets up your environment for such advanced workflows, enabling you to automatically and systematically improve your transformer model’s training parameters."
      ],
      "metadata": {
        "id": "oSfvOpUqRHW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate ray[tune] optuna -U\n",
        "\n"
      ],
      "metadata": {
        "id": "ZE-ubxrUkUOv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "feb344f5-b10f-4ce8-d1c5-5a27479b5bc0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting ray[tune]\n",
            "  Downloading ray-2.51.1-cp312-cp312-manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Collecting click!=8.3.0,>=7.0 (from ray[tune])\n",
            "  Downloading click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.12/dist-packages (from ray[tune]) (4.25.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ray[tune]) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from ray[tune]) (5.29.5)\n",
            "Collecting tensorboardX>=1.9 (from ray[tune])\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.1)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray[tune]) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray[tune]) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray[tune]) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema->ray[tune]) (0.28.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.2.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-22.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (47.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading ray-2.51.1-cp312-cp312-manylinux2014_x86_64.whl (71.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, pyarrow, colorlog, click, optuna, ray, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.3.0\n",
            "    Uninstalling click-8.3.0:\n",
            "      Successfully uninstalled click-8.3.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed click-8.2.1 colorlog-6.10.1 datasets-4.4.1 optuna-4.5.0 pyarrow-22.0.0 ray-2.51.1 tensorboardX-2.6.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "pyarrow"
                ]
              },
              "id": "0d79df4de42243f49425facf200bcb09"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code sets seeds for all relevant libraries to ensure full reproducibility in PyTorch experiments. It also defines evaluation metrics for question answering Exact Match (EM) and F1 Score then builds a Hugging Face Trainer with arguments perfectly suited for BERT-style extractive QA training and validation. These steps are essential for stable, trackable QA research and applications.\n",
        "\n",
        "**Input**\n",
        "\n",
        "    Seed value (here, 42), set across Python, numpy, PyTorch CPU and GPU.\n",
        "\n",
        "    Model predictions and gold answers for each evaluation batch.\n",
        "\n",
        "    Training datasets, pretrained model, and tokenizer.\n",
        "\n",
        "**Output**\n",
        "\n",
        "    Reproducible training and validation runs.\n",
        "\n",
        "    Dictionary of computed evaluation metrics (averaged EM, F1, and inference time) after each evaluation phase.\n",
        "\n",
        "    A fully configured Trainer object for orchestrated fine-tuning on QA tasks.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "Ensures all sources of randomness are controlled, making repeated experiments yield consistent results.\n",
        "\n",
        "python\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(prediction.strip().lower() == truth.strip().lower())\n",
        "\n",
        "Computes an all-or-nothing score: 1 only if predicted span matches gold answer exactly, after stripping and lowercasing.\n",
        "\n",
        "python\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = prediction.lower().split()\n",
        "    truth_tokens = truth.lower().split()\n",
        "    ...\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "Calculates the token-level overlap F1 between prediction and gold answer. Captures partial matches as well as perfect ones.\n",
        "\n",
        "python\n",
        "def compute_metrics(eval_pred):\n",
        "    ...\n",
        "    return metrics\n",
        "\n",
        "Processes batched model predictions, decodes answer spans, computes EM and F1 across all examples, and averages them.\n",
        "\n",
        "python\n",
        "training_args = TrainingArguments(...)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "Sets up training parameters (epochs, batch sizes, device, logging, saving) and bundles everything in a Trainer for easy use.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "text\n",
        "{'Exact_Match': 0.76, 'F1_Score': 0.81, 'Avg_Inference_Time': 0.0052}\n",
        "\n",
        "(A dictionary summarizing model accuracy and efficiency, printed after evaluation.)\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "Setting all seeds eliminates nearly all nondeterminism—so you're not chasing \"lucky runs,\" which is essential in QA research."
      ],
      "metadata": {
        "id": "-Q1g705kuwek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(prediction.strip().lower() == truth.strip().lower())\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = prediction.lower().split()\n",
        "    truth_tokens = truth.lower().split()\n",
        "\n",
        "    common = set(pred_tokens) & set(truth_tokens)\n",
        "    if not common:\n",
        "        return 0.0\n",
        "\n",
        "    precision = len(common) / len(pred_tokens)\n",
        "    recall = len(common) / len(truth_tokens)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    start_time = time.time()\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    start_logits, end_logits = predictions\n",
        "\n",
        "\n",
        "    start_positions = np.argmax(start_logits, axis=1)\n",
        "    end_positions = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    exact_matches = []\n",
        "    f1_scores = []\n",
        "\n",
        "\n",
        "    for i in range(len(start_positions)):\n",
        "        input_ids = tokenized_eval[i][\"input_ids\"]\n",
        "        pred_tokens = input_ids[start_positions[i]: end_positions[i] + 1]\n",
        "        pred_text = tokenizer.decode(pred_tokens, skip_special_tokens=True)\n",
        "\n",
        "        gold_text = eval_data[i][\"Answer\"]\n",
        "\n",
        "        exact_matches.append(compute_exact_match(pred_text, gold_text))\n",
        "        f1_scores.append(compute_f1(pred_text, gold_text))\n",
        "\n",
        "    avg_inference_time = (time.time() - start_time) / len(start_positions)\n",
        "\n",
        "    metrics = {\n",
        "        \"Exact_Match\": np.mean(exact_matches),\n",
        "        \"F1_Score\": np.mean(f1_scores),\n",
        "        \"Avg_Inference_Time\": avg_inference_time\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/results\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"/content/drive/My Drive/logs\",\n",
        "    learning_rate=4e-5,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    data_seed=42\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "eJPYKdMNz2r8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda316bf-9f48-466d-b3ec-333b985d0cd4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-478015526.py:86: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **With Grid Search**"
      ],
      "metadata": {
        "id": "2qL2ZF7slsvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Description\n",
        "\n",
        "This code establishes a reproducible environment for training a BERT-based question answering model, defines evaluation metrics (Exact Match and F1), sets hyperparameters and training arguments for model fine-tuning, and implements an automated hyperparameter grid search using Optuna integrated with Hugging Face’s Trainer. After the search, it outputs the best hyperparameters and prints results from all trials for detailed analysis.\n",
        "\n",
        "**Input**\n",
        "\n",
        "    Tokenized train and evaluation datasets (tokenized_train and tokenized_eval) with questions, contexts, and answers.\n",
        "\n",
        "    Pretrained model and tokenizer for BERT-based question answering.\n",
        "\n",
        "    Defined hyperparameter search space including learning rate, batch size, and number of epochs.\n",
        "\n",
        "    Utility functions for computing Exact Match and F1 evaluation metrics.\n",
        "\n",
        "    A seed value (42) to ensure deterministic and reproducible training runs.\n",
        "\n",
        "**Output**\n",
        "\n",
        "    Metric results for each hyperparameter trial during grid search.\n",
        "\n",
        "    The best hyperparameter configuration found according to the evaluation (maximizing F1 Score).\n",
        "\n",
        "    A DataFrame printed to the console with all trial results sorted by performance metric.\n",
        "\n",
        "    Messages indicating the progress and results of the hyperparameter search.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    Seeds different RNGs and configures CUDA backend for reproducible results.\n",
        "\n",
        "python\n",
        "def compute_exact_match(prediction, truth):\n",
        "    ...\n",
        "def compute_f1(prediction, truth):\n",
        "    ...\n",
        "def compute_metrics(eval_pred):\n",
        "    ...\n",
        "\n",
        "    Define evaluation metric functions that compute Exact Match, F1 score, and average inference time from model predictions and ground truth answers.\n",
        "\n",
        "python\n",
        "def tune_hp(trial):\n",
        "    learning_rate = trial.suggest_categorical(\"learning_rate\", [5e-5, 3e-5, 1e-5])\n",
        "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16])\n",
        "    num_train_epochs = trial.suggest_categorical(\"num_train_epochs\", [3, 4, 5])\n",
        "    return {...}\n",
        "\n",
        "    Hyperparameter search space definition for Optuna trials.\n",
        "\n",
        "python\n",
        "def model_init():\n",
        "    return BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "    Function to reinitialize the model freshly for each hyperparameter trial to avoid weight contamination.\n",
        "\n",
        "python\n",
        "grid_trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=grid_training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "    Trainer setup for hyperparameter search using the reinitialization function and grid search training arguments.\n",
        "\n",
        "python\n",
        "best_trial = grid_trainer.hyperparameter_search(\n",
        "    backend=\"optuna\",\n",
        "    hp_space=tune_hp,\n",
        "    direction=\"maximize\",\n",
        "    n_trials=18,\n",
        ")\n",
        "\n",
        "    Executes Optuna-powered hyperparameter search over 18 trials, maximizing the F1 metric.\n",
        "\n",
        "python\n",
        "df_results = pd.DataFrame(trial_results)\n",
        "df_results.sort_values(\"metric_value\", ascending=False, inplace=True)\n",
        "print(df_results)\n",
        "\n",
        "    Converts trial results to a DataFrame, sorts them by performance, and prints them for more interpretable analysis.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "text\n",
        "--- Starting Grid Search ---\n",
        "[I 2025-11-08 21:15:30,000] Trial 0 finished with value: 0.76\n",
        "...\n",
        "--- Grid Search Complete ---\n",
        "BEST HYPERPARAMETERS FOUND:\n",
        "{'learning_rate': 3e-5, 'per_device_train_batch_size': 8, 'num_train_epochs': 5}\n",
        "\n",
        "Grid Search Trial Results (sorted by metric):\n",
        "   learning_rate  per_device_train_batch_size  num_train_epochs  metric_value\n",
        "1        3e-05                           8                5          0.78\n",
        "0        5e-05                          16                4          0.76\n",
        "...\n",
        "\n",
        "Best hyperparameters detail:\n",
        "learning_rate                3e-05\n",
        "per_device_train_batch_size      8\n",
        "num_train_epochs                5\n",
        "metric_value                 0.78\n",
        "Name: 1, dtype: object\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "This code robustly integrates reproducibility best practices with automatic hyperparameter tuning for transformer QA modeling, using Optuna’s search capabilities tightly coupled with Hugging Face Trainer. The use of a fresh model initialization per trial ensures unbiased evaluation of each hyperparameter set."
      ],
      "metadata": {
        "id": "iwP0-y9Qmo7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from transformers import TrainingArguments, Trainer, set_seed\n",
        "\n",
        "import optuna\n",
        "\n",
        "seed_value = 42\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(prediction.strip().lower() == truth.strip().lower())\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = prediction.lower().split()\n",
        "    truth_tokens = truth.lower().split()\n",
        "    common = set(pred_tokens) & set(truth_tokens)\n",
        "    if not common:\n",
        "        return 0.0\n",
        "    precision = len(common) / len(pred_tokens)\n",
        "    recall = len(common) / len(truth_tokens)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    start_time = time.time()\n",
        "    predictions, labels = eval_pred\n",
        "    start_logits, end_logits = predictions\n",
        "    start_positions = np.argmax(start_logits, axis=1)\n",
        "    end_positions = np.argmax(end_logits, axis=1)\n",
        "    exact_matches = []\n",
        "    f1_scores = []\n",
        "    for i in range(len(start_positions)):\n",
        "        input_ids = tokenized_eval[i][\"input_ids\"]\n",
        "        pred_tokens = input_ids[start_positions[i]: end_positions[i] + 1]\n",
        "        pred_text = tokenizer.decode(pred_tokens, skip_special_tokens=True)\n",
        "        gold_text = eval_data[i][\"Answer\"]\n",
        "        exact_matches.append(compute_exact_match(pred_text, gold_text))\n",
        "        f1_scores.append(compute_f1(pred_text, gold_text))\n",
        "    avg_inference_time = (time.time() - start_time) / len(start_positions)\n",
        "    metrics = {\n",
        "        \"Exact_Match\": np.mean(exact_matches),\n",
        "        \"F1_Score\": np.mean(f1_scores),\n",
        "        \"Avg_Inference_Time\": avg_inference_time\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# Define training arguments (hyperparameters)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/results\", # Changed to Google Drive\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"/content/drive/My Drive/logs\", # Changed to Google Drive\n",
        "    learning_rate=4e-5,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    data_seed=42\n",
        ")\n",
        "\n",
        "\n",
        "def tune_hp(trial):\n",
        "    learning_rate = trial.suggest_categorical(\"learning_rate\", [5e-5, 3e-5, 1e-5])\n",
        "    per_device_train_batch_size = trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16])\n",
        "    num_train_epochs = trial.suggest_categorical(\"num_train_epochs\", [3, 4, 5])  # New hyperparameter for epochs\n",
        "    return {\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"per_device_train_batch_size\": per_device_train_batch_size,\n",
        "        \"num_train_epochs\": num_train_epochs,\n",
        "    }\n",
        "\n",
        "grid_training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/grid_search_results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    load_best_model_at_end=False,\n",
        "    metric_for_best_model=\"eval_F1_Score\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\",\n",
        "    num_train_epochs=3,\n",
        "    warmup_steps=500,\n",
        "    logging_dir=\"/content/drive/My Drive/grid_search_logs\",\n",
        ")\n",
        "\n",
        "def model_init():\n",
        "\n",
        "    return BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "grid_trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=grid_training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "print(\"\\n--- Starting Grid Search ---\")\n",
        "best_trial = grid_trainer.hyperparameter_search(\n",
        "    backend=\"optuna\",\n",
        "    hp_space=tune_hp,\n",
        "    direction=\"maximize\",\n",
        "    n_trials=18,\n",
        ")\n",
        "\n",
        "if best_trial:\n",
        "    print(\"\\n--- Grid Search Complete ---\")\n",
        "    print(\"BEST HYPERPARAMETERS FOUND:\")\n",
        "    print(best_trial)\n",
        "    best_hps = best_trial.hyperparameters\n",
        "    print(\"\\nBest Hyperparameters:\")\n",
        "    for key, val in best_hps.items():\n",
        "        print(f\"  {key}: {val}\")\n",
        "else:\n",
        "    print(\"Search failed or no best trial found.\")\n",
        "\n",
        "print(\"\\nYou can now initialize TrainingArguments with best_hps for final training.\")\n",
        "\n",
        "\n",
        "\n",
        "if grid_trainer.hp_search_backend and grid_trainer.hp_search_backend.study:\n",
        "    all_trials = grid_trainer.hp_search_backend.study.get_trials()\n",
        "\n",
        "\n",
        "    trial_results = []\n",
        "    for trial in all_trials:\n",
        "        vals = trial.params.copy()\n",
        "\n",
        "        vals['metric_value'] = trial.value\n",
        "        trial_results.append(vals)\n",
        "\n",
        "    df_results = pd.DataFrame(trial_results)\n",
        "\n",
        "\n",
        "    df_results.sort_values(\"metric_value\", ascending=False, inplace=True)\n",
        "\n",
        "    print(\"\\nGrid Search Trial Results (sorted by metric):\")\n",
        "    print(df_results)\n",
        "\n",
        "\n",
        "    print(\"\\nBest hyperparameters detail:\")\n",
        "    print(df_results.iloc[0])\n",
        "else:\n",
        "    print(\"\\nCould not retrieve trial results from the study.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j1taXROhlwKB",
        "outputId": "39bd8103-d560-41c7-8dd0-8716a8543009"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2642510910.py:105: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  grid_trainer = Trainer(\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[I 2025-11-08 14:50:14,436] A new study created in memory with name: no-name-93edb277-3782-4bbd-9b6d-1d49a75a4b85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Grid Search ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 00:54, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.561098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237803</td>\n",
              "      <td>0.001281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.011742</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117332</td>\n",
              "      <td>0.003260</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.879116</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020504</td>\n",
              "      <td>0.002383</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:51:17,204] Trial 0 finished with value: 0.02288724535352977 and parameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 3}. Best is trial 0 with value: 0.02288724535352977.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 00:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.169468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095487</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.898768</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117830</td>\n",
              "      <td>0.001457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.189728</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198351</td>\n",
              "      <td>0.002886</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:52:10,306] Trial 1 finished with value: 0.20123753796077903 and parameters: {'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3}. Best is trial 1 with value: 0.20123753796077903.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 00:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.169468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098141</td>\n",
              "      <td>0.001426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.898782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.117610</td>\n",
              "      <td>0.000767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.189480</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198058</td>\n",
              "      <td>0.000765</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:53:00,076] Trial 2 finished with value: 0.1988229946566938 and parameters: {'learning_rate': 1e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3}. Best is trial 1 with value: 0.20123753796077903.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='355' max='355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [355/355 01:26, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.134999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.000992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.950027</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.326712</td>\n",
              "      <td>0.000803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.891041</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.821497</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025741</td>\n",
              "      <td>0.001074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.932394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062296</td>\n",
              "      <td>0.000825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:54:27,898] Trial 3 finished with value: 0.06312078816287812 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 5}. Best is trial 1 with value: 0.20123753796077903.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='284' max='284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [284/284 01:07, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.560705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.235636</td>\n",
              "      <td>0.000792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.033477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.103114</td>\n",
              "      <td>0.001070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.886484</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.019772</td>\n",
              "      <td>0.000711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.905676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217533</td>\n",
              "      <td>0.000775</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:55:36,887] Trial 4 finished with value: 0.2183079076599477 and parameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 4}. Best is trial 4 with value: 0.2183079076599477.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='71' max='284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 71/284 00:16 < 00:51, 4.10 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.135839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195611</td>\n",
              "      <td>0.001205</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:55:54,672] Trial 5 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 00:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.560444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.237803</td>\n",
              "      <td>0.000777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.015892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.119330</td>\n",
              "      <td>0.000733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.883060</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.001059</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:56:47,286] Trial 6 finished with value: 0.019002213843886135 and parameters: {'learning_rate': 5e-05, 'per_device_train_batch_size': 8, 'num_train_epochs': 3}. Best is trial 4 with value: 0.2183079076599477.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='71' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 71/213 00:16 < 00:34, 4.12 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.135082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.195587</td>\n",
              "      <td>0.000803</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:57:05,049] Trial 7 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='71' max='355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 71/355 00:16 < 01:09, 4.11 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.135082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.196364</td>\n",
              "      <td>0.001236</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:57:22,873] Trial 8 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 00:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009367</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108641</td>\n",
              "      <td>0.000768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.894826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225395</td>\n",
              "      <td>0.000849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.879309</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.296071</td>\n",
              "      <td>0.000785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:58:11,286] Trial 9 finished with value: 0.2968559928084098 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 3}. Best is trial 9 with value: 0.2968559928084098.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 01:01, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108641</td>\n",
              "      <td>0.000737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.894730</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225136</td>\n",
              "      <td>0.001139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.879935</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.296071</td>\n",
              "      <td>0.000822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.274859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.345724</td>\n",
              "      <td>0.000787</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 14:59:14,865] Trial 10 finished with value: 0.34651100628764797 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 4}. Best is trial 10 with value: 0.34651100628764797.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 01:01, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108823</td>\n",
              "      <td>0.000754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.894401</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225395</td>\n",
              "      <td>0.001127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.879143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.296071</td>\n",
              "      <td>0.000773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.277247</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347941</td>\n",
              "      <td>0.000812</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 15:00:18,530] Trial 11 finished with value: 0.34875268419384425 and parameters: {'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 4}. Best is trial 11 with value: 0.34875268419384425.\n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 36/144 00:15 < 00:47, 2.26 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009436</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108641</td>\n",
              "      <td>0.000733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 15:00:34,786] Trial 12 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 72/144 00:30 < 00:31, 2.28 it/s, Epoch 2/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009340</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108823</td>\n",
              "      <td>0.000985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.894119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.223696</td>\n",
              "      <td>0.000784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 15:01:06,723] Trial 13 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 72/144 00:30 < 00:31, 2.29 it/s, Epoch 2/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009311</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108823</td>\n",
              "      <td>0.000793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.894951</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.223696</td>\n",
              "      <td>0.000863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 15:01:38,528] Trial 14 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 36/144 00:15 < 00:47, 2.26 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.169468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.095487</td>\n",
              "      <td>0.000728</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 15:01:54,884] Trial 15 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 72/144 00:30 < 00:31, 2.29 it/s, Epoch 2/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108823</td>\n",
              "      <td>0.000755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.894104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.224901</td>\n",
              "      <td>0.000830</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 15:02:26,909] Trial 16 pruned. \n",
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='72' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 72/144 00:30 < 00:31, 2.29 it/s, Epoch 2/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.009380</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.108823</td>\n",
              "      <td>0.000770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.894675</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.223696</td>\n",
              "      <td>0.000797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-08 15:02:58,785] Trial 17 pruned. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Grid Search Complete ---\n",
            "BEST HYPERPARAMETERS FOUND:\n",
            "BestRun(run_id='11', objective=0.34875268419384425, hyperparameters={'learning_rate': 3e-05, 'per_device_train_batch_size': 16, 'num_train_epochs': 4}, run_summary=None)\n",
            "\n",
            "Best Hyperparameters:\n",
            "  learning_rate: 3e-05\n",
            "  per_device_train_batch_size: 16\n",
            "  num_train_epochs: 4\n",
            "\n",
            "You can now initialize TrainingArguments with best_hps for final training.\n",
            "\n",
            "Could not retrieve trial results from the study.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **With Random Search**"
      ],
      "metadata": {
        "id": "E8zdKOR1RAB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code performs a random hyperparameter search for fine-tuning a BERT question answering model using Hugging Face’s Trainer API. It sets global reproducibility seeds, defines evaluation metrics (Exact Match and F1), and iteratively trains multiple models with randomly chosen hyperparameters (learning rate, batch size, epochs). Each trial trains a fresh model instance, evaluates performance, and stores results for later analysis.\n",
        "\n",
        "**Input**\n",
        "\n",
        "    Tokenized training and evaluation datasets (tokenized_train and tokenized_eval).\n",
        "\n",
        "    Pretrained BERT question answering model and its corresponding tokenizer.\n",
        "\n",
        "    Defined search space for three hyperparameters: learning rate, batch size, and number of training epochs.\n",
        "\n",
        "    Seed value for deterministic behavior and reproducibility.\n",
        "\n",
        "**Output**\n",
        "\n",
        "    Training and evaluation metrics (Exact Match, F1 Score, average inference time) for each hyperparameter trial.\n",
        "\n",
        "    Training time per trial.\n",
        "\n",
        "    A sorted pandas DataFrame showing results of all trials ranked by F1 score.\n",
        "\n",
        "    Display of the best-performing hyperparameter combination identified from the random search.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    Sets global random seeds and CUDA deterministic behavior to ensure reproducible results.\n",
        "\n",
        "python\n",
        "def compute_metrics(eval_pred):\n",
        "    ...\n",
        "    return metrics\n",
        "\n",
        "    Defines the evaluation function computing Exact Match, F1 Score, and average inference time by decoding predicted token spans back to text.\n",
        "\n",
        "python\n",
        "args = copy.deepcopy(base_training_args)\n",
        "args.per_device_train_batch_size = batch_size\n",
        "args.learning_rate = lr\n",
        "args.num_train_epochs = epochs\n",
        "args.seed = seed_value + trial_num\n",
        "\n",
        "    Creates an independent set of training arguments for each trial with randomized hyperparameters and a unique seed.\n",
        "\n",
        "python\n",
        "trainer = Trainer(\n",
        "    model=BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device),\n",
        "    args=args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "    Initializes a fresh Trainer for each trial with a new model instance and associated hyperparameters.\n",
        "\n",
        "python\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "    Runs training and evaluation phases for each trial.\n",
        "\n",
        "python\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.sort_values(\"eval_f1_score\", ascending=False, inplace=True)\n",
        "\n",
        "    Aggregates trial results into a DataFrame and sorts by evaluation F1 score to identify the best trial.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "text\n",
        "Trial 4: Learning Rate=3e-05, Batch Size=16, Epochs=5\n",
        "...\n",
        "Random Search Results Sorted by F1 Score:\n",
        "   trial  learning_rate  batch_size  epochs  train_time_sec  eval_exact_match  eval_f1_score  eval_avg_inference_time\n",
        "3      4        3e-05          16       5         1189.32              0.75           0.80                  0.0051\n",
        "...\n",
        "Best Hyperparameters:\n",
        "trial                  4\n",
        "learning_rate       3e-05\n",
        "batch_size            16\n",
        "epochs                 5\n",
        "train_time_sec     1189.32\n",
        "eval_exact_match    0.75\n",
        "eval_f1_score       0.80\n",
        "eval_avg_inference_time 0.0051\n",
        "Name: 3, dtype: object\n",
        "\n",
        "Comment and Observation\n",
        "\n",
        "This implementation follows a straightforward randomized hyperparameter search strategy, ensuring each trial is statistically independent by reseeding and initializing a new model."
      ],
      "metadata": {
        "id": "EkWGThV8nOq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from transformers import TrainingArguments, Trainer, set_seed\n",
        "from transformers.data.data_collator import default_data_collator\n",
        "from transformers import BertForQuestionAnswering  # Make sure you import your model\n",
        "import optuna\n",
        "import copy\n",
        "\n",
        "seed_value = 42\n",
        "np.random.seed(seed_value)\n",
        "torch.manual_seed(seed_value)\n",
        "torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(prediction.strip().lower() == truth.strip().lower())\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = prediction.lower().split()\n",
        "    truth_tokens = truth.lower().split()\n",
        "    common = set(pred_tokens) & set(truth_tokens)\n",
        "    if not common:\n",
        "        return 0.0\n",
        "    precision = len(common) / len(pred_tokens)\n",
        "    recall = len(common) / len(truth_tokens)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    start_time = time.time()\n",
        "    predictions, labels = eval_pred\n",
        "    start_logits, end_logits = predictions\n",
        "    start_positions = np.argmax(start_logits, axis=1)\n",
        "    end_positions = np.argmax(end_logits, axis=1)\n",
        "    exact_matches = []\n",
        "    f1_scores = []\n",
        "    for i in range(len(start_positions)):\n",
        "        input_ids = tokenized_eval[i][\"input_ids\"]\n",
        "        pred_tokens = input_ids[start_positions[i]: end_positions[i] + 1]\n",
        "        pred_text = tokenizer.decode(pred_tokens, skip_special_tokens=True)\n",
        "        gold_text = eval_data[i][\"Answer\"]\n",
        "        exact_matches.append(compute_exact_match(pred_text, gold_text))\n",
        "        f1_scores.append(compute_f1(pred_text, gold_text))\n",
        "    avg_inference_time = (time.time() - start_time) / len(start_positions)\n",
        "    metrics = {\n",
        "        \"Exact_Match\": np.mean(exact_matches),\n",
        "        \"F1_Score\": np.mean(f1_scores),\n",
        "        \"Avg_Inference_Time\": avg_inference_time\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "\n",
        "base_training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/random_search_results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"/content/drive/My Drive/random_search_logs\",\n",
        "    learning_rate=4e-5,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[],\n",
        "\n",
        "    seed=42,\n",
        "    data_seed=42,\n",
        ")\n",
        "\n",
        "\n",
        "random.seed(seed_value)\n",
        "\n",
        "num_trials = 18\n",
        "results = []\n",
        "\n",
        "for trial_num in range(1, num_trials + 1):\n",
        "\n",
        "    lr = random.choice([5e-5, 3e-5, 1e-5])\n",
        "    batch_size = random.choice([8, 16])\n",
        "    epochs = random.choice([3, 4, 5])\n",
        "\n",
        "    print(f\"\\nTrial {trial_num}: Learning Rate={lr}, Batch Size={batch_size}, Epochs={epochs}\")\n",
        "\n",
        "\n",
        "    args = copy.deepcopy(base_training_args)\n",
        "    args.per_device_train_batch_size = batch_size\n",
        "    args.per_device_eval_batch_size = batch_size\n",
        "    args.learning_rate = lr\n",
        "    args.num_train_epochs = epochs\n",
        "    args.output_dir = f\"/content/drive/My Drive/random_search_results/trial_{trial_num}\"\n",
        "\n",
        "    args.seed = seed_value + trial_num\n",
        "    args.data_seed = seed_value + trial_num\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device),\n",
        "        args=args,\n",
        "        train_dataset=tokenized_train,\n",
        "        eval_dataset=tokenized_eval,\n",
        "        compute_metrics=compute_metrics,\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=default_data_collator,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    trainer.train()\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    metrics = trainer.evaluate()\n",
        "\n",
        "    results.append({\n",
        "        \"trial\": trial_num,\n",
        "        \"learning_rate\": lr,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs,\n",
        "        \"train_time_sec\": train_time,\n",
        "        \"eval_exact_match\": metrics.get(\"eval_Exact_Match\"),\n",
        "        \"eval_f1_score\": metrics.get(\"eval_F1_Score\"),\n",
        "        \"eval_avg_inference_time\": metrics.get(\"eval_Avg_Inference_Time\"),\n",
        "    })\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.sort_values(\"eval_f1_score\", ascending=False, inplace=True)\n",
        "\n",
        "print(\"\\nRandom Search Results Sorted by F1 Score:\")\n",
        "display(df_results)\n",
        "\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "display(df_results.iloc[0])"
      ],
      "metadata": {
        "id": "pC7OT3k3RDqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ddee44e-4aa9-4eea-d975-6546a4493994"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1: Learning Rate=1e-05, Batch Size=8, Epochs=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-3857617530.py:104: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 00:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.983701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111600</td>\n",
              "      <td>0.000722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.064300</td>\n",
              "      <td>4.704707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219678</td>\n",
              "      <td>0.000761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.756400</td>\n",
              "      <td>3.674100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.319048</td>\n",
              "      <td>0.000821</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 2: Learning Rate=5e-05, Batch Size=16, Epochs=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [180/180 01:16, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.864092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164926</td>\n",
              "      <td>0.001136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.325779</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219094</td>\n",
              "      <td>0.000785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.158500</td>\n",
              "      <td>2.173169</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.271548</td>\n",
              "      <td>0.000806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.158500</td>\n",
              "      <td>1.900278</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.158500</td>\n",
              "      <td>1.876008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074347</td>\n",
              "      <td>0.000737</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 3: Learning Rate=3e-05, Batch Size=8, Epochs=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 00:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.486810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.168350</td>\n",
              "      <td>0.000747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.795700</td>\n",
              "      <td>3.341656</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.341755</td>\n",
              "      <td>0.000797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.209700</td>\n",
              "      <td>1.917612</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018539</td>\n",
              "      <td>0.000715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 4: Learning Rate=3e-05, Batch Size=16, Epochs=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 01:01, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.057562</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.212314</td>\n",
              "      <td>0.000757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.968213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.268551</td>\n",
              "      <td>0.000781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.562600</td>\n",
              "      <td>3.790273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.326573</td>\n",
              "      <td>0.000808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.562600</td>\n",
              "      <td>2.115113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.264201</td>\n",
              "      <td>0.000764</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 5: Learning Rate=5e-05, Batch Size=16, Epochs=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 00:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.904035</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.191229</td>\n",
              "      <td>0.000771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.383355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.254797</td>\n",
              "      <td>0.000782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.180600</td>\n",
              "      <td>2.265693</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.322808</td>\n",
              "      <td>0.000879</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 6: Learning Rate=3e-05, Batch Size=8, Epochs=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='284' max='284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [284/284 01:07, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.395769</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208279</td>\n",
              "      <td>0.001068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.778200</td>\n",
              "      <td>2.905244</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343269</td>\n",
              "      <td>0.000894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.967100</td>\n",
              "      <td>1.908113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.967100</td>\n",
              "      <td>1.843800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.128543</td>\n",
              "      <td>0.001105</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 7: Learning Rate=1e-05, Batch Size=16, Epochs=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 00:46, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.014236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.069681</td>\n",
              "      <td>0.000736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.743755</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.099555</td>\n",
              "      <td>0.000936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.903800</td>\n",
              "      <td>5.122689</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.148255</td>\n",
              "      <td>0.000769</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 8: Learning Rate=5e-05, Batch Size=16, Epochs=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 01:01, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.708737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.143472</td>\n",
              "      <td>0.001036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.389945</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227909</td>\n",
              "      <td>0.000798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.148800</td>\n",
              "      <td>2.892556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.306425</td>\n",
              "      <td>0.000828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.148800</td>\n",
              "      <td>1.860859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.026923</td>\n",
              "      <td>0.000734</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 9: Learning Rate=3e-05, Batch Size=16, Epochs=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 01:01, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.069349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200905</td>\n",
              "      <td>0.001234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.080105</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.176783</td>\n",
              "      <td>0.001251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.592600</td>\n",
              "      <td>3.813518</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.238855</td>\n",
              "      <td>0.000822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.592600</td>\n",
              "      <td>2.200797</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.280889</td>\n",
              "      <td>0.000789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 10: Learning Rate=5e-05, Batch Size=8, Epochs=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 00:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.876513</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129772</td>\n",
              "      <td>0.001016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.375800</td>\n",
              "      <td>1.982022</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018539</td>\n",
              "      <td>0.000766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.236900</td>\n",
              "      <td>1.981170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 11: Learning Rate=3e-05, Batch Size=8, Epochs=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='355' max='355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [355/355 01:24, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.586625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.267894</td>\n",
              "      <td>0.001122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.830400</td>\n",
              "      <td>2.894347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.295170</td>\n",
              "      <td>0.000878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.045400</td>\n",
              "      <td>1.879840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3.045400</td>\n",
              "      <td>1.830453</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.775400</td>\n",
              "      <td>1.933125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.064490</td>\n",
              "      <td>0.000723</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 12: Learning Rate=1e-05, Batch Size=8, Epochs=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='284' max='284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [284/284 01:07, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.933566</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.112529</td>\n",
              "      <td>0.000716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.089800</td>\n",
              "      <td>4.618569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.202398</td>\n",
              "      <td>0.001107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.702300</td>\n",
              "      <td>3.246699</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311729</td>\n",
              "      <td>0.000813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.702300</td>\n",
              "      <td>1.953852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000703</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 13: Learning Rate=5e-05, Batch Size=16, Epochs=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [180/180 01:16, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.881423</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.175839</td>\n",
              "      <td>0.000750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.414400</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.273777</td>\n",
              "      <td>0.001038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.192600</td>\n",
              "      <td>2.234987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.345864</td>\n",
              "      <td>0.000791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.192600</td>\n",
              "      <td>1.856277</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.192600</td>\n",
              "      <td>1.880855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.086606</td>\n",
              "      <td>0.000806</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 14: Learning Rate=5e-05, Batch Size=8, Epochs=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 00:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.544921</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.269496</td>\n",
              "      <td>0.001017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.229200</td>\n",
              "      <td>1.959491</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020494</td>\n",
              "      <td>0.000797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.217000</td>\n",
              "      <td>1.851912</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020886</td>\n",
              "      <td>0.000713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 15: Learning Rate=1e-05, Batch Size=8, Epochs=4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='284' max='284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [284/284 01:07, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.907475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.198700</td>\n",
              "      <td>0.001174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.033500</td>\n",
              "      <td>4.595242</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.199794</td>\n",
              "      <td>0.000814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.630100</td>\n",
              "      <td>3.040465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.300789</td>\n",
              "      <td>0.000791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.630100</td>\n",
              "      <td>1.987139</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024496</td>\n",
              "      <td>0.001047</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 16: Learning Rate=5e-05, Batch Size=16, Epochs=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [180/180 01:16, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.894642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.212264</td>\n",
              "      <td>0.000780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.286855</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.302245</td>\n",
              "      <td>0.000935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.109300</td>\n",
              "      <td>2.148203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.331361</td>\n",
              "      <td>0.000832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.109300</td>\n",
              "      <td>1.865143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020110</td>\n",
              "      <td>0.000732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>5.109300</td>\n",
              "      <td>1.830909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036626</td>\n",
              "      <td>0.001034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 17: Learning Rate=1e-05, Batch Size=8, Epochs=3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 00:50, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.024662</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.217208</td>\n",
              "      <td>0.000776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.106600</td>\n",
              "      <td>4.789709</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257456</td>\n",
              "      <td>0.000793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.788800</td>\n",
              "      <td>3.424017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.343958</td>\n",
              "      <td>0.001219</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 18: Learning Rate=5e-05, Batch Size=8, Epochs=5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='355' max='355' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [355/355 01:23, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.508865</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285296</td>\n",
              "      <td>0.000792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>5.305100</td>\n",
              "      <td>1.950616</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020457</td>\n",
              "      <td>0.000707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.225700</td>\n",
              "      <td>1.827825</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.001147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.225700</td>\n",
              "      <td>1.979432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.047433</td>\n",
              "      <td>0.000724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.603100</td>\n",
              "      <td>2.000849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.124879</td>\n",
              "      <td>0.000739</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Search Results Sorted by F1 Score:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    trial  learning_rate  batch_size  epochs  train_time_sec  \\\n",
              "16     17        0.00001           8       3       51.064417   \n",
              "4       5        0.00005          16       3       46.995197   \n",
              "0       1        0.00001           8       3       51.301821   \n",
              "8       9        0.00003          16       4       62.373662   \n",
              "3       4        0.00003          16       4       62.209715   \n",
              "6       7        0.00001          16       3       46.980091   \n",
              "5       6        0.00003           8       4       68.232312   \n",
              "17     18        0.00005           8       5       84.058161   \n",
              "12     13        0.00005          16       5       76.957572   \n",
              "1       2        0.00005          16       5       77.271131   \n",
              "10     11        0.00003           8       5       84.852308   \n",
              "15     16        0.00005          16       5       76.994967   \n",
              "7       8        0.00005          16       4       62.346051   \n",
              "14     15        0.00001           8       4       67.741972   \n",
              "13     14        0.00005           8       3       51.018846   \n",
              "2       3        0.00003           8       3       51.407157   \n",
              "9      10        0.00005           8       3       51.180945   \n",
              "11     12        0.00001           8       4       67.899343   \n",
              "\n",
              "    eval_exact_match  eval_f1_score  eval_avg_inference_time  \n",
              "16               0.0       0.343958                 0.000815  \n",
              "4                0.0       0.322808                 0.000781  \n",
              "0                0.0       0.319048                 0.000789  \n",
              "8                0.0       0.280889                 0.000897  \n",
              "3                0.0       0.264201                 0.000996  \n",
              "6                0.0       0.148255                 0.000860  \n",
              "5                0.0       0.128543                 0.001031  \n",
              "17               0.0       0.124879                 0.000747  \n",
              "12               0.0       0.086606                 0.000802  \n",
              "1                0.0       0.074347                 0.001034  \n",
              "10               0.0       0.064490                 0.000721  \n",
              "15               0.0       0.036626                 0.001183  \n",
              "7                0.0       0.026923                 0.000722  \n",
              "14               0.0       0.024496                 0.000997  \n",
              "13               0.0       0.020886                 0.000730  \n",
              "2                0.0       0.018539                 0.001043  \n",
              "9                0.0       0.017943                 0.000758  \n",
              "11               0.0       0.017943                 0.000750  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ff8d979-71f7-43af-907a-96f6033b70df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trial</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>epochs</th>\n",
              "      <th>train_time_sec</th>\n",
              "      <th>eval_exact_match</th>\n",
              "      <th>eval_f1_score</th>\n",
              "      <th>eval_avg_inference_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>51.064417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343958</td>\n",
              "      <td>0.000815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>46.995197</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.322808</td>\n",
              "      <td>0.000781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>51.301821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.319048</td>\n",
              "      <td>0.000789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>62.373662</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.280889</td>\n",
              "      <td>0.000897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>62.209715</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.264201</td>\n",
              "      <td>0.000996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>46.980091</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.148255</td>\n",
              "      <td>0.000860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>68.232312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.128543</td>\n",
              "      <td>0.001031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>84.058161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124879</td>\n",
              "      <td>0.000747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>76.957572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.086606</td>\n",
              "      <td>0.000802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>77.271131</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074347</td>\n",
              "      <td>0.001034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>84.852308</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.064490</td>\n",
              "      <td>0.000721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>16</td>\n",
              "      <td>5</td>\n",
              "      <td>76.994967</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.036626</td>\n",
              "      <td>0.001183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>62.346051</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026923</td>\n",
              "      <td>0.000722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>67.741972</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.024496</td>\n",
              "      <td>0.000997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>51.018846</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.020886</td>\n",
              "      <td>0.000730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.00003</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>51.407157</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018539</td>\n",
              "      <td>0.001043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>0.00005</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>51.180945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>0.00001</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>67.899343</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017943</td>\n",
              "      <td>0.000750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ff8d979-71f7-43af-907a-96f6033b70df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6ff8d979-71f7-43af-907a-96f6033b70df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6ff8d979-71f7-43af-907a-96f6033b70df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-097453f9-dc4e-4c1a-a7a5-f4d18addb24d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-097453f9-dc4e-4c1a-a7a5-f4d18addb24d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-097453f9-dc4e-4c1a-a7a5-f4d18addb24d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7e26d8ef-8cb5-42f1-b5f9-f0ff3a1de994\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7e26d8ef-8cb5-42f1-b5f9-f0ff3a1de994 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"trial\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 1,\n        \"max\": 18,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          17,\n          5,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"learning_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7149858514250885e-05,\n        \"min\": 1e-05,\n        \"max\": 5e-05,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1e-05,\n          5e-05,\n          3e-05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch_size\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 8,\n        \"max\": 16,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          16,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train_time_sec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.828538647136998,\n        \"min\": 46.980090856552124,\n        \"max\": 84.85230755805969,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          51.064417123794556,\n          46.99519658088684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_exact_match\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_f1_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12102534172205938,\n        \"min\": 0.017943187058586323,\n        \"max\": 0.3439575803498149,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.3439575803498149\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_avg_inference_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00014163615282254235,\n        \"min\": 0.0007214428673327809,\n        \"max\": 0.0011828734841145261,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          0.0008152991953030438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Hyperparameters:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "trial                      17.000000\n",
              "learning_rate               0.000010\n",
              "batch_size                  8.000000\n",
              "epochs                      3.000000\n",
              "train_time_sec             51.064417\n",
              "eval_exact_match            0.000000\n",
              "eval_f1_score               0.343958\n",
              "eval_avg_inference_time     0.000815\n",
              "Name: 16, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>trial</th>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>learning_rate</th>\n",
              "      <td>0.000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>batch_size</th>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epochs</th>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train_time_sec</th>\n",
              "      <td>51.064417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_exact_match</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_f1_score</th>\n",
              "      <td>0.343958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eval_avg_inference_time</th>\n",
              "      <td>0.000815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Execution (Evaluation)**"
      ],
      "metadata": {
        "id": "dWy6J1HBJVYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The First Execution (From Previous Activity)**"
      ],
      "metadata": {
        "id": "mmLJy4pAOHTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code block manages the full run of fine-tuning a BERT-based question answering model. It sets random seeds for reproducibility, trains the model, evaluates its performance, saves the trained model checkpoint, and communicates progress to the user.\n",
        "\n",
        "**Input**\n",
        "\n",
        "    The trainer object: A Hugging Face Trainer instance preconfigured with model, datasets, hyperparameters, metrics, and tokenizer.\n",
        "\n",
        "    Model saving path: './bert_qa_best' for checkpoint storage.\n",
        "\n",
        "**Output**\n",
        "\n",
        "    Console messages detailing the start of training, evaluation results, and completion status.\n",
        "\n",
        "    Printed evaluation metrics such as F1 Score and Exact Match after training.\n",
        "\n",
        "    Model checkpoint saved to disk for future inference tasks.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "set_seed(42)\n",
        "\n",
        "Ensures all random processes (Python, NumPy, Torch) are seeded, producing reliable and repeatable results.\n",
        "\n",
        "python\n",
        "trainer.train()\n",
        "\n",
        "Starts model fine-tuning using configured settings on your training data.\n",
        "\n",
        "python\n",
        "trainer.evaluate()\n",
        "\n",
        "Computes performance metrics on your validation or evaluation dataset.\n",
        "\n",
        "python\n",
        "trainer.save_model(\"./bert_qa_best\")\n",
        "\n",
        "Saves the trained model, tokenizer, and config to a specified directory for later use.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "--- Starting Fine-Tuning (Expected Time: 1–4 hours on GPU) ---\n",
        "\n",
        "[Training progress output]\n",
        "\n",
        "--- Final Evaluation Results ---\n",
        "{'eval_loss': 0.95, 'eval_Exact_Match': 0.77, 'eval_F1_Score': 0.82, ...}\n",
        "\n",
        "Fine-tuning process complete. The resulting model can now be used for Inference (Stage 4).\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "In this block, you see a typical workflow for preparing a BERT QA model: not just training, but also evaluating, saving, and documenting progress in clear stages."
      ],
      "metadata": {
        "id": "AFVtUKgRs22W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "\n",
        "print(\"\\n--- Starting Fine-Tuning (Expected Time: 1–4 hours on GPU) ---\")\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "print(\"\\n--- Final Evaluation Results ---\")\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n",
        "\n",
        "Save the best model checkpoint for later Inference\n",
        "trainer.save_model(\"./bert_qa_best\")\n",
        "\n",
        "print(\"\\n Fine-tuning process complete. The resulting model can now be used for Inference (Stage 4).\")\n"
      ],
      "metadata": {
        "id": "aPpb02yu0_l8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "9aef26cc-d5cd-4091-aac2-c691025c555c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2606965218.py, line 20)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2606965218.py\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    Save the best model checkpoint for later Inference\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code block kicks off and completes the fine-tuning process for your BERT-based question answering model using the best hyperparameters from your random search. It ensures reproducibility, performs model training, evaluates performance, saves the model checkpoint, and provides feedback for your workflow status.\n",
        "\n",
        "**Input**\n",
        "\n",
        "    An initialized trainer object (already set up with best random search hyperparameters, model, datasets, metrics, and tokenizer).\n",
        "\n",
        "    A Google Drive save path for the best checkpoint.\n",
        "\n",
        "**Output**\n",
        "\n",
        "    Progress and status messages in the console about the training, evaluation, and model saving stages.\n",
        "\n",
        "    Final evaluation metrics displayed (like F1 and Exact Match for your validation set).\n",
        "\n",
        "    A saved model checkpoint in Google Drive, ready for use during inference (Stage 4).\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "set_seed(42)\n",
        "\n",
        "    Fixes random seeds for all libraries, ensuring results are reproducible across different runs.\n",
        "\n",
        "python\n",
        "trainer.train()\n",
        "\n",
        "    Trains your BERT QA model on the training data using the best hyperparameters from your random search.\n",
        "\n",
        "python\n",
        "trainer.evaluate()\n",
        "\n",
        "    Evaluates the trained model's performance on your held-out validation dataset.\n",
        "\n",
        "python\n",
        "trainer.save_model(\"/content/drive/My Drive/bert_qa_best_random_hps\")\n",
        "\n",
        "    Saves the complete, fine-tuned model checkpoint to Google Drive so you can load it later for question-answering tasks.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "\n",
        "--- Starting Fine-Tuning with Best Hyperparameters (Expected Time: 1–4 hours on GPU) ---\n",
        "\n",
        "[284/284 02:38, Epoch 4/4]\n",
        "Epoch \tTraining Loss \tValidation Loss \tExact Match \tF1 Score \tAvg Inference Time\n",
        "1 \tNo log \t1.811164 \t0.000000 \t0.034671 \t0.000789\n",
        "2 \t1.607500 \t1.942523 \t0.000000 \t0.235041 \t0.001137\n",
        "3 \t1.159300 \t2.277214 \t0.000000 \t0.270486 \t0.002345\n",
        "4 \t1.159300 \t2.429585 \t0.000000 \t0.294740 \t0.000993\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "This phase puts your best-found hyperparameters into practice, ensuring the training results you see are reliable and repeatable by setting the seed."
      ],
      "metadata": {
        "id": "Dnh8h45Rrmp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "print(\"\\n--- Starting Fine-Tuning with Best Hyperparameters (Expected Time: 1–4 hours on GPU) ---\")\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n--- Final Evaluation Results with Best Hyperparameters ---\")\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n",
        "\n",
        "trainer.save_model(\"/content/drive/My Drive/bert_qa_best_random_hps\")\n",
        "\n",
        "print(\"\\n Fine-tuning process complete with best hyperparameters. The resulting model can now be used for Inference (Stage 4).\")"
      ],
      "metadata": {
        "id": "rg_mh4I3Qrq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Execution using the best hyperparameters found (Grid Search)**"
      ],
      "metadata": {
        "id": "CUL-24JbDKgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code configures and initializes a Hugging Face Trainer using the best hyperparameters obtained from a prior grid search for fine-tuning a BERT question answering model. It sets up training arguments such as learning rate, batch size, number of epochs, and device preferences, then prepares the trainer with the selected datasets, metrics, and tokenizer for the final training run.\n",
        "\n",
        "**Input**\n",
        "\n",
        "    Best hyperparameters dictionary (best_hps) containing keys: num_train_epochs, per_device_train_batch_size, and learning_rate discovered from grid search.\n",
        "\n",
        "    Pretrained BERT model instance (model).\n",
        "\n",
        "    Tokenized training and evaluation datasets (tokenized_train and tokenized_eval).\n",
        "\n",
        "    Predefined evaluation metric function (compute_metrics).\n",
        "\n",
        "    Tokenizer for data collation.\n",
        "\n",
        "    Default data collator to handle batch preparation.\n",
        "\n",
        "**Output**\n",
        "\n",
        "    An initialized Trainer object configured to train the model using the best hyperparameters.\n",
        "\n",
        "    Printed confirmation output displaying the current training arguments, including directories, learning rate, batch size, and other settings.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "best_training_args = TrainingArguments(\n",
        "    output_dir=...,\n",
        "    num_train_epochs=best_hps['num_train_epochs'],\n",
        "    per_device_train_batch_size=best_hps['per_device_train_batch_size'],\n",
        "    learning_rate=best_hps['learning_rate'],\n",
        "    ...\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    seed=42,\n",
        "    data_seed=42,\n",
        ")\n",
        "\n",
        "    Creates training argument instance using the best hyperparameters while maintaining consistent logging and saving configurations.\n",
        "\n",
        "python\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=best_training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "    Sets up the Hugging Face Trainer with the finalized arguments, enabling efficient training and evaluation.\n",
        "\n",
        "python\n",
        "print(best_training_args)\n",
        "\n",
        "    Prints the training configuration to confirm settings prior to starting training.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "\n",
        "TrainingArguments(\n",
        "  output_dir=/content/drive/My Drive/results_best_hps,\n",
        "  num_train_epochs=5,\n",
        "  per_device_train_batch_size=8,\n",
        "  per_device_eval_batch_size=8,\n",
        "  warmup_steps=500,\n",
        "  weight_decay=0.01,\n",
        "  learning_rate=3e-05,\n",
        "  logging_dir=/content/drive/My Drive/logs_best_hps,\n",
        "  save_strategy=epoch,\n",
        "  eval_strategy=epoch,\n",
        "  load_best_model_at_end=True,\n",
        "  fp16=True,\n",
        "  seed=42,\n",
        "  data_seed=42,\n",
        ")\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "This code completes the model fine-tuning pipeline by initializing the Trainer with carefully selected hyperparameters validated through grid search. Using load_best_model_at_end=True ensures that the best checkpoint saved during training will be loaded for final evaluations or deployment."
      ],
      "metadata": {
        "id": "1XX5jCmxoTe6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad4d048f",
        "outputId": "d2d57140-7eb3-4bca-ec33-d70cf07c7ad8"
      },
      "source": [
        "\n",
        "best_training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/results_best_hps\",\n",
        "    num_train_epochs=best_hps['num_train_epochs'],\n",
        "    per_device_train_batch_size=best_hps['per_device_train_batch_size'],\n",
        "    per_device_eval_batch_size=best_hps['per_device_train_batch_size'],\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"/content/drive/My Drive/logs_best_hps\",\n",
        "    learning_rate=best_hps['learning_rate'],\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    data_seed=42\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=best_training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "print(\"\\n--- Initialized Trainer with Best Hyperparameters ---\")\n",
        "print(best_training_args)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initialized Trainer with Best Hyperparameters ---\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=42,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.EPOCH,\n",
            "eval_use_gather_object=False,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/My Drive/logs_best_hps,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=100,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=4,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/My Drive/results_best_hps,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=16,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.EPOCH,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=500,\n",
            "weight_decay=0.01,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2315262293.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Description\n",
        "\n",
        "This code block performs the final stages of BERT-based question answering model fine-tuning, including:\n",
        "\n",
        "    Training the model using previously identified best hyperparameters.\n",
        "\n",
        "    Evaluating the fine-tuned model's performance on the evaluation dataset.\n",
        "\n",
        "    Saving the trained model checkpoint for future inference.\n",
        "\n",
        "    Ensuring all random seeds are set for reproducibility.\n",
        "\n",
        "Input\n",
        "\n",
        "    The trainer object: configured with your best hyperparameters, model, datasets, tokenizer, and metric function.\n",
        "\n",
        "    Google Drive path for saving the model checkpoint (as a string).\n",
        "\n",
        "Output\n",
        "\n",
        "    Console messages indicating the progress of training and evaluation.\n",
        "\n",
        "    Printed final evaluation metrics (like F1 Score, Exact Match).\n",
        "\n",
        "    The trained model saved in your specified Google Drive directory for Stage 4 (Inference).\n",
        "\n",
        "Essential Syntaxes\n",
        "\n",
        "python\n",
        "set_seed(42)\n",
        "\n",
        "    Fixes all Python and GPU-related random sources to make training and evaluation reproducible.\n",
        "\n",
        "python\n",
        "trainer.train()\n",
        "\n",
        "    Triggers model fine-tuning (training) using the best hyperparameters found during search.\n",
        "\n",
        "python\n",
        "trainer.evaluate()\n",
        "\n",
        "    Runs evaluation on the held-out dataset to report final performance metrics.\n",
        "\n",
        "python\n",
        "trainer.save_model(\"/content/drive/My Drive/bert_qa_best_hps\")\n",
        "\n",
        "    Saves a complete checkpoint of your trained model (weights, config, and tokenizer) to Google Drive. You can reload this checkpoint later for QA inference.\n",
        "\n",
        "Example Output\n",
        "\n",
        "text\n",
        "--- Starting Fine-Tuning with Best Hyperparameters (Expected Time: 1–4 hours on GPU) ---\n",
        "\n",
        "[Training progress output]\n",
        "\n",
        "--- Final Evaluation Results with Best Hyperparameters ---\n",
        "{'eval_loss': 1.02, 'eval_Exact_Match': 0.76, 'eval_F1_Score': 0.81, ...}\n",
        "\n",
        "Fine-tuning process complete with best hyperparameters. The resulting model can now be used for Inference (Stage 4).\n",
        "\n",
        "Comment and Observation\n",
        "\n",
        "This final phase puts everything together: your model is trained on the best settings, thoroughly evaluated, and safely saved for later use."
      ],
      "metadata": {
        "id": "lDvFu1X_qODE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "826bf16c",
        "outputId": "6556e0d6-77d1-4f3d-c21f-0f32d1b2dca9"
      },
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "\n",
        "print(\"\\n--- Starting Fine-Tuning with Best Hyperparameters (Expected Time: 1–4 hours on GPU) ---\")\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "print(\"\\n--- Final Evaluation Results with Best Hyperparameters ---\")\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n",
        "\n",
        "trainer.save_model(\"/content/drive/My Drive/bert_qa_best_hps\")\n",
        "\n",
        "print(\"\\n Fine-tuning process complete with best hyperparameters. The resulting model can now be used for Inference (Stage 4).\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Fine-Tuning with Best Hyperparameters (Expected Time: 1–4 hours on GPU) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='144' max='144' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [144/144 01:32, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.018747</td>\n",
              "      <td>0.007042</td>\n",
              "      <td>0.266756</td>\n",
              "      <td>0.000814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.291263</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.227263</td>\n",
              "      <td>0.001024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>5.619400</td>\n",
              "      <td>3.783773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.276288</td>\n",
              "      <td>0.002263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5.619400</td>\n",
              "      <td>2.121073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.173171</td>\n",
              "      <td>0.000872</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Evaluation Results with Best Hyperparameters ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 2.121073007583618, 'eval_Exact_Match': 0.0, 'eval_F1_Score': 0.1731714489590942, 'eval_Avg_Inference_Time': 0.0009119880031531965, 'eval_runtime': 1.1836, 'eval_samples_per_second': 119.971, 'eval_steps_per_second': 7.604, 'epoch': 4.0}\n",
            "\n",
            " Fine-tuning process complete with best hyperparameters. The resulting model can now be used for Inference (Stage 4).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Execution using the best hyperparameters found (Random Search)**"
      ],
      "metadata": {
        "id": "Xpl6mXprDVDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code block sets up a Hugging Face Trainer to fine-tune a BERT-based question answering model using the best hyperparameters found from a random search. It extracts the optimal combination of hyperparameters from your trial results and configures the training process to use these settings for a final training run.\n",
        "Input\n",
        "\n",
        "    best_hps_random_search: A dictionary containing the best hyperparameters (epochs, batch_size, learning_rate) identified during random search.\n",
        "\n",
        "    Pretrained model and tokenizer for BERT QA.\n",
        "\n",
        "    Tokenized training and evaluation datasets (tokenized_train, tokenized_eval).\n",
        "\n",
        "    Previously defined metric function (compute_metrics).\n",
        "\n",
        "**Output**\n",
        "\n",
        "    An initialized Trainer object configured with the selected best hyperparameters—ready for fine-tuning and evaluation.\n",
        "\n",
        "    Printed confirmation of the training arguments for transparency and tracking.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "best_hps_random_search = df_results.iloc[0].to_dict()\n",
        "\n",
        "    Grabs the best hyperparameter set as a Python dictionary from your sorted trial results DataFrame.\n",
        "\n",
        "python\n",
        "best_training_args_random_search = TrainingArguments(\n",
        "    output_dir=...,  # folder for saving model outputs\n",
        "    num_train_epochs=int(best_hps_random_search['epochs']),\n",
        "    per_device_train_batch_size=int(best_hps_random_search['batch_size']),\n",
        "    learning_rate=best_hps_random_search['learning_rate'],\n",
        "    ...\n",
        ")\n",
        "\n",
        "    Initializes TrainingArguments with the values from your best random search trial.\n",
        "\n",
        "python\n",
        "trainer_random_search = Trainer(\n",
        "    model=BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device),\n",
        "    args=best_training_args_random_search,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "    Prepares a new Trainer object with all required settings for final training.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
        "\n",
        "\n",
        "--- Initialized Trainer with Best Hyperparameters from Random Search ---\n",
        "TrainingArguments(\n",
        "_n_gpu=1,\n",
        "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
        "adafactor=False,\n",
        "adam_beta1=0.9,\n",
        "adam_beta2=0.999,\n",
        "adam_epsilon=1e-08,\n",
        "auto_find_batch_size=False,\n",
        "average_tokens_across_devices=True,\n",
        "batch_eval_metrics=False,\n",
        "bf16=False,\n",
        "bf16_full_eval=False,\n",
        "data_seed=42,\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "This block ensures you are leveraging the most effective hyperparameter configuration discovered during random search. By saving outputs and logs to Google Drive, results and checkpoints are preserved for later validation or deployment"
      ],
      "metadata": {
        "id": "fNRfTg_wqk0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_hps_random_search = df_results.iloc[0].to_dict()\n",
        "\n",
        "\n",
        "best_training_args_random_search = TrainingArguments(\n",
        "    output_dir=\"/content/drive/My Drive/results_best_hps_random_search\",\n",
        "    num_train_epochs=int(best_hps_random_search['epochs']),\n",
        "    per_device_train_batch_size=int(best_hps_random_search['batch_size']),\n",
        "    per_device_eval_batch_size=int(best_hps_random_search['batch_size']),\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"/content/drive/My Drive/logs_best_hps_random_search\",\n",
        "    learning_rate=best_hps_random_search['learning_rate'],\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[],\n",
        "    seed=42,\n",
        "    data_seed=42\n",
        ")\n",
        "\n",
        "\n",
        "trainer_random_search = Trainer(\n",
        "    model=BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device),\n",
        "    args=best_training_args_random_search,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=default_data_collator,\n",
        ")\n",
        "\n",
        "print(\"\\n--- Initialized Trainer with Best Hyperparameters from Random Search ---\")\n",
        "print(best_training_args_random_search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPvK-UZmCwun",
        "outputId": "25c9fbfa-b66a-447c-9633-c5d744bc148a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initialized Trainer with Best Hyperparameters from Random Search ---\n",
            "TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=42,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.EPOCH,\n",
            "eval_use_gather_object=False,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=no,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=1e-05,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=/content/drive/My Drive/logs_best_hps_random_search,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=100,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/My Drive/results_best_hps_random_search,\n",
            "overwrite_output_dir=False,\n",
            "parallelism_config=None,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.EPOCH,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cpu=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=500,\n",
            "weight_decay=0.01,\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-93913365.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer_random_search = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function Description\n",
        "\n",
        "This code performs the final round of fine-tuning for your BERT-based QA model using the best hyperparameters discovered from random search. It takes care to set seeds for reproducibility, starts model training, evaluates your model, saves the best checkpoint, and prints friendly, readable progress updates throughout.\n",
        "Input\n",
        "\n",
        "    The trainer_random_search object: a Hugging Face Trainer, pre-loaded with the model, datasets, tokenizer, metrics, and best random search hyperparameters.\n",
        "\n",
        "    Save path for the trained model checkpoint (here: /content/drive/My Drive/bert_qa_best_random_hps).\n",
        "\n",
        "Output\n",
        "\n",
        "    Console logs and printed messages showing the start, completion, and high-level metrics of fine-tuning and evaluation.\n",
        "\n",
        "    Final evaluation dictionary (eval_results_random_search) summarizing performance (e.g., F1 Score, Exact Match).\n",
        "\n",
        "    Saved model checkpoint for future inference.\n",
        "\n",
        "Essential Syntaxes\n",
        "\n",
        "python\n",
        "set_seed(42)\n",
        "\n",
        "Sets all sources of randomness in your environment. This is crucial for reliable, repeatable experiments.\n",
        "\n",
        "python\n",
        "trainer_random_search.train()\n",
        "\n",
        "Begins fine-tuning using best random search settings. This usually takes 1–4 hours with a GPU — so sit back, maybe grab a coffee while it runs!\n",
        "\n",
        "​\n",
        "\n",
        "python\n",
        "trainer_random_search.evaluate()\n",
        "\n",
        "Checks the model against your validation set and reports metrics, helping you measure how successful fine-tuning was.\n",
        "\n",
        "python\n",
        "trainer_random_search.save_model(...)\n",
        "\n",
        "Stores your fully trained model on Google Drive, so you don’t need to retrain later.\n",
        "Example Output\n",
        "\n",
        "text\n",
        "--- Starting Fine-Tuning with Best Hyperparameters from Random Search (Expected Time: 1–4 hours on GPU) ---\n",
        "\n",
        "[Training progress output]\n",
        "\n",
        "--- Final Evaluation Results with Best Hyperparameters from Random Search ---\n",
        "{'eval_loss': 0.98, 'eval_Exact_Match': 0.80, 'eval_F1_Score': 0.87, ...}\n",
        "\n",
        "Fine-tuning process complete with best hyperparameters from random search. The resulting model can now be used for Inference (Stage 4).\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "This workflow is designed to be user-friendly and transparent: you get clear status updates before, during, and after training. This is just a test Dr. Raga but as you can see this is the flow that we want to build which is q & a essay type."
      ],
      "metadata": {
        "id": "tvehdkEjKFR9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "4afe6f6c",
        "outputId": "9c5bd6c7-6e40-4b5e-a4d2-c88cb792e848"
      },
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "print(\"\\n--- Starting Fine-Tuning with Best Hyperparameters from Random Search (Expected Time: 1–4 hours on GPU) ---\")\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "\n",
        "trainer_random_search.train()\n",
        "\n",
        "print(\"\\n--- Final Evaluation Results with Best Hyperparameters from Random Search ---\")\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "eval_results_random_search = trainer_random_search.evaluate()\n",
        "print(eval_results_random_search)\n",
        "\n",
        "trainer_random_search.save_model(\"/content/drive/My Drive/bert_qa_best_random_hps\")\n",
        "\n",
        "print(\"\\n Fine-tuning process complete with best hyperparameters from random search. The resulting model can now be used for Inference (Stage 4).\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Fine-Tuning with Best Hyperparameters from Random Search (Expected Time: 1–4 hours on GPU) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='213' max='213' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [213/213 01:20, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Exact Match</th>\n",
              "      <th>F1 Score</th>\n",
              "      <th>Avg Inference Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.973124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111054</td>\n",
              "      <td>0.000730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>6.068700</td>\n",
              "      <td>4.714879</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.224718</td>\n",
              "      <td>0.001380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.762800</td>\n",
              "      <td>3.688576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.311595</td>\n",
              "      <td>0.001053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Evaluation Results with Best Hyperparameters from Random Search ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18/18 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 3.6885762214660645, 'eval_Exact_Match': 0.0, 'eval_F1_Score': 0.31159524856842297, 'eval_Avg_Inference_Time': 0.0008031818228708186, 'eval_runtime': 1.234, 'eval_samples_per_second': 115.069, 'eval_steps_per_second': 14.586, 'epoch': 3.0}\n",
            "\n",
            " Fine-tuning process complete with best hyperparameters from random search. The resulting model can now be used for Inference (Stage 4).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DsKw_cKTIqSQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actual Testing**"
      ],
      "metadata": {
        "id": "QWTDiCCgJZVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function Description**\n",
        "\n",
        "This code creates an interactive question-answering session using a Hugging Face model pipeline. For each question from your DataFrame, it poses the question, gets your answer, compares it to the ground truth using exact match and F1 metrics, and also measures the semantic similarity using embeddings and cosine similarity. It uses the Hugging Face pipeline utility for simple and effective inference.\n",
        "\n",
        "**Input**\n",
        "\n",
        "    df: A DataFrame containing columns \"Question\", \"Context\", and \"Answer\" for each example.\n",
        "\n",
        "    User input (your answer to each posed question).\n",
        "\n",
        "**Output**\n",
        "\n",
        "    Prints detailed evaluation for each test round: ground truth, model's predicted answer, your answer, Exact Match, F1 score, cosine similarity, and inference time.\n",
        "\n",
        "**Essential Syntaxes**\n",
        "\n",
        "python\n",
        "qna_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device_num\n",
        ")\n",
        "\n",
        "    Sets up a question-answering pipeline using your fine-tuned model and tokenizer. Uses GPU if available, else CPU.\n",
        "\n",
        "python\n",
        "def get_embedding(text, tokenizer, model):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.bert(**inputs)\n",
        "    return outputs.last_hidden_state[0][0].cpu().numpy()\n",
        "\n",
        "    Computes the embedding for a given text by passing it through the base BERT model. Used to compare semantic similarity of answers.\n",
        "\n",
        "python\n",
        "bert_result = qna_pipeline({\"question\": row['Question'], \"context\": row['Context']})\n",
        "\n",
        "    Performs inference: predicts the answer span using the model.\n",
        "\n",
        "python\n",
        "exact = compute_exact_match(user_answer, row['Answer'])\n",
        "f1 = compute_f1(user_answer, row['Answer'])\n",
        "\n",
        "    Calculates the exact match and F1 metrics for your answer against the reference answer.\n",
        "\n",
        "python\n",
        "cos_sim = cosine_similarity([user_emb], [gt_emb])[0][0]\n",
        "\n",
        "    Finds cosine similarity (semantic closeness) between your answer and the ground truth, using embeddings.\n",
        "\n",
        "**Example Output**\n",
        "\n",
        "text\n",
        "Question: 1\n",
        "What does GeeksforGeeks provide?\n",
        "Please type your answer:\n",
        "<user types>\n",
        "\n",
        "Evaluation\n",
        "Ground Truth Answer: resources for computer science\n",
        "Model Predicted Answer: resources for computer science\n",
        "Your Answer: resources for computer science\n",
        "Exact Match: 1\n",
        "F1 Score: 1.0000\n",
        "Cosine Similarity: 1.0000\n",
        "Inference Time (BERT QA): 0.1122 seconds\n",
        "\n",
        "**Comment and Observation**\n",
        "\n",
        "This approach is ideal for human-in-the-loop evaluation. You can check your own understanding, see how the model performs, and compare results both exactly (Exact Match, F1) and by semantics (cosine similarity of embeddings)."
      ],
      "metadata": {
        "id": "7yr1pifb8rGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "device_num = 0 if torch.cuda.is_available() else -1\n",
        "question_times = 0\n",
        "\n",
        "\n",
        "qna_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device_num\n",
        ")\n",
        "\n",
        "def get_embedding(text, tokenizer, model):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.bert(**inputs)\n",
        "    return outputs.last_hidden_state[0][0].cpu().numpy()\n",
        "\n",
        "def interactive_test(df):\n",
        "\n",
        "    row = df.sample(n=1).iloc[0]\n",
        "\n",
        "\n",
        "    print(\"\\nQuestion:\", question_times)\n",
        "    print(row['Question'])\n",
        "\n",
        "\n",
        "    user_answer = input(\"\\nPlease type your answer:\\n\")\n",
        "\n",
        "\n",
        "    start = time.time()\n",
        "    bert_result = qna_pipeline({\n",
        "        \"question\": row['Question'],\n",
        "        \"context\": row['Context']\n",
        "    })\n",
        "    inference_time = time.time() - start\n",
        "\n",
        "\n",
        "    exact = compute_exact_match(user_answer, row['Answer'])\n",
        "    f1 = compute_f1(user_answer, row['Answer'])\n",
        "\n",
        "    user_emb = get_embedding(user_answer, tokenizer, model)\n",
        "    gt_emb = get_embedding(row['Answer'], tokenizer, model)\n",
        "\n",
        "    cos_sim = cosine_similarity([user_emb], [gt_emb])[0][0]\n",
        "\n",
        "    print(\"\\n--- Evaluation ---\")\n",
        "    print(f\"Ground Truth Answer: {row['Answer']}\")\n",
        "    print(f\"Model Predicted Answer: {bert_result['answer']}\")\n",
        "    print(f\"Your Answer: {user_answer}\")\n",
        "    print(f\"Exact Match: {exact}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Cosine Similarity: {cos_sim:.4f}\")\n",
        "    print(f\"Inference Time (BERT QA): {inference_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "\n",
        "while question_times < 10:\n",
        "    interactive_test(df)\n",
        "    question_times += 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SCFl34Gv5NV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "04ed5c75-52bd-4909-d725-a3097410ddeb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question: 0\n",
            "What is the fundamental purpose of a vector embedding, and what types of data can it represent for machine learning models?\n",
            "\n",
            "Please type your answer:\n",
            "Converting text into numerical representaiton\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation ---\n",
            "Ground Truth Answer: Their fundamental purpose is to serve as numerical representations of data points, expressing nonmathematical data like words or images as an array of numbers that ML models can process.\n",
            "Model Predicted Answer: Vector embeddings\n",
            "Your Answer: Converting text into numerical representaiton\n",
            "Exact Match: 0\n",
            "F1 Score: 0.0588\n",
            "Cosine Similarity: 0.6943\n",
            "Inference Time (BERT QA): 0.0734 seconds\n",
            "\n",
            "Question: 1\n",
            "What elimination strategy does Hyperband employ for early stopping, how does successive halving progressively reduce the configuration pool, and what selection criterion determines which configurations advance through iterations?\n",
            "\n",
            "Please type your answer:\n",
            "idk\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation ---\n",
            "Ground Truth Answer: Hyperband uses successive halving for early stopping, removing the worst-performing half after each training round and carrying the top 50 forward until one optimal configuration remains.\n",
            "Model Predicted Answer: This\n",
            "Your Answer: idk\n",
            "Exact Match: 0\n",
            "F1 Score: 0.0000\n",
            "Cosine Similarity: 0.3365\n",
            "Inference Time (BERT QA): 0.0150 seconds\n",
            "\n",
            "Question: 2\n",
            "What two sampling dimensions do subsample and colsamplebytree control in XGBoost training, and how do they respectively regulate data and feature utilization during model construction?\n",
            "\n",
            "Please type your answer:\n",
            "subsample sets data sample percentage per training round, and colsample_bytree sets feature percentage for tree construction.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Evaluation ---\n",
            "Ground Truth Answer: subsample sets data sample percentage per training round, and colsamplebytree sets feature percentage for tree construction.\n",
            "Model Predicted Answer: subsample\n",
            "Your Answer: subsample sets data sample percentage per training round, and colsample_bytree sets feature percentage for tree construction.\n",
            "Exact Match: 0\n",
            "F1 Score: 0.8125\n",
            "Cosine Similarity: 0.9936\n",
            "Inference Time (BERT QA): 0.0140 seconds\n",
            "\n",
            "Question: 3\n",
            "What must be considered to ensure a successful linear-regression analysis?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2451848670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mquestion_times\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0minteractive_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mquestion_times\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2451848670.py\u001b[0m in \u001b[0;36minteractive_test\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0muser_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPlease type your answer:\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}