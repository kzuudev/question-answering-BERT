{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "aJIx9GC8IbTw"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c476fdb38d174937888fe6c398eb6387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc5ba260884b45bc8dcfdf6a9b0da7a2",
              "IPY_MODEL_a657d760f37f4a3c90e6ec7fd8ef6535",
              "IPY_MODEL_ac160a5790794692a21ad2241bd6a277"
            ],
            "layout": "IPY_MODEL_6d91b7577b2b4cd5806e1203ed140b2f"
          }
        },
        "fc5ba260884b45bc8dcfdf6a9b0da7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8fc8c35ad95b4c44a53f27c349c6e39e",
            "placeholder": "​",
            "style": "IPY_MODEL_aa7c967464874097bea69b21419bb64c",
            "value": "Map: 100%"
          }
        },
        "a657d760f37f4a3c90e6ec7fd8ef6535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ac6a96ceae04010aadb43a549478b60",
            "max": 568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_144b46aad4784fd0963e49c147ca9362",
            "value": 568
          }
        },
        "ac160a5790794692a21ad2241bd6a277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_684a02e2696148d5a03b729c50344140",
            "placeholder": "​",
            "style": "IPY_MODEL_ddd7e12993404ee59696b193e9e151be",
            "value": " 568/568 [00:00&lt;00:00, 5234.26 examples/s]"
          }
        },
        "6d91b7577b2b4cd5806e1203ed140b2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fc8c35ad95b4c44a53f27c349c6e39e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa7c967464874097bea69b21419bb64c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ac6a96ceae04010aadb43a549478b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "144b46aad4784fd0963e49c147ca9362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "684a02e2696148d5a03b729c50344140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddd7e12993404ee59696b193e9e151be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "050497efd49d47df81703adeb97fe9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c36f94904cbc408dad215dce1061e3e6",
              "IPY_MODEL_67f12e28219a4169b5bba9df768a7529",
              "IPY_MODEL_c8ac9e5f950241119853e382246b4e5d"
            ],
            "layout": "IPY_MODEL_b424fcd4870248ed9208b612f598ae26"
          }
        },
        "c36f94904cbc408dad215dce1061e3e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0421c0457724f898a138b3a9fac4361",
            "placeholder": "​",
            "style": "IPY_MODEL_2be2d021b19446dbb754f6543f07ae4f",
            "value": "Map: 100%"
          }
        },
        "67f12e28219a4169b5bba9df768a7529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecac224058354346a8775d1e2ae7d452",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff9c8bb07b4347e0ad691814874f2de1",
            "value": 142
          }
        },
        "c8ac9e5f950241119853e382246b4e5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea39cec509fe4cfab50ca77e45a6de14",
            "placeholder": "​",
            "style": "IPY_MODEL_63f791be91a1405d8abea3855570f738",
            "value": " 142/142 [00:00&lt;00:00, 3078.18 examples/s]"
          }
        },
        "b424fcd4870248ed9208b612f598ae26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0421c0457724f898a138b3a9fac4361": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2be2d021b19446dbb754f6543f07ae4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ecac224058354346a8775d1e2ae7d452": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff9c8bb07b4347e0ad691814874f2de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea39cec509fe4cfab50ca77e45a6de14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f791be91a1405d8abea3855570f738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69668b0e7f984367a2e940a390130324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_193fa850bf64455e97629dd4fbda9c87",
              "IPY_MODEL_47c286eabf8f4e80a0ff2e95248e8395",
              "IPY_MODEL_a0a74fdfba184c4ea377e1462dad5b93"
            ],
            "layout": "IPY_MODEL_dce349668ceb4f6391c6ee41678d0c94"
          }
        },
        "193fa850bf64455e97629dd4fbda9c87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e7589ffa72435ea3dd13e9368c7afe",
            "placeholder": "​",
            "style": "IPY_MODEL_68840400ca6c4bc89a2ee9cf874b8bb5",
            "value": "Map: 100%"
          }
        },
        "47c286eabf8f4e80a0ff2e95248e8395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f585c1b27534a7daa5cdc24c7e721e8",
            "max": 568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2480293a1114453a6f279fd71d30a78",
            "value": 568
          }
        },
        "a0a74fdfba184c4ea377e1462dad5b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fadb950901345b7ae8c977743ab00a3",
            "placeholder": "​",
            "style": "IPY_MODEL_9360e28880b047058a0497da5c720be5",
            "value": " 568/568 [00:00&lt;00:00, 1171.66 examples/s]"
          }
        },
        "dce349668ceb4f6391c6ee41678d0c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e7589ffa72435ea3dd13e9368c7afe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68840400ca6c4bc89a2ee9cf874b8bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f585c1b27534a7daa5cdc24c7e721e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2480293a1114453a6f279fd71d30a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fadb950901345b7ae8c977743ab00a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9360e28880b047058a0497da5c720be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "143e42839a08430eb23613f520d4c201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd2072c854214edbb3698ef30f95c021",
              "IPY_MODEL_d458a4e7230140e59f596fb7587c2d07",
              "IPY_MODEL_22c8cc9d114c414a971fd1e55e65a0f5"
            ],
            "layout": "IPY_MODEL_e370c67ac0c940468477e928c77b98ff"
          }
        },
        "fd2072c854214edbb3698ef30f95c021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5c963838a8b4cb0b0e53f05189cfae0",
            "placeholder": "​",
            "style": "IPY_MODEL_38a1b0e400d044cd81c5227f79042a44",
            "value": "Map: 100%"
          }
        },
        "d458a4e7230140e59f596fb7587c2d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7f9da76a46941d4b5173adf408822ed",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60c6327a29474260a08c4d7372b95542",
            "value": 142
          }
        },
        "22c8cc9d114c414a971fd1e55e65a0f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb99c9ccf3324629afa0dad021d35618",
            "placeholder": "​",
            "style": "IPY_MODEL_bd4666b68fee425f857196b254b51d62",
            "value": " 142/142 [00:00&lt;00:00, 675.49 examples/s]"
          }
        },
        "e370c67ac0c940468477e928c77b98ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5c963838a8b4cb0b0e53f05189cfae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38a1b0e400d044cd81c5227f79042a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7f9da76a46941d4b5173adf408822ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60c6327a29474260a08c4d7372b95542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb99c9ccf3324629afa0dad021d35618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd4666b68fee425f857196b254b51d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "551fb5ab03dc4fec9c78399eb4c8ef0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2437c2ab4e3455d8c1e1f73f19fb194",
              "IPY_MODEL_7a913ac6684a4275a1a45e8a8e593f35",
              "IPY_MODEL_0437ca2134404edfa5a8fe7acac74626"
            ],
            "layout": "IPY_MODEL_4cc18bbf4eda4a2cb14f202fe72e7bdf"
          }
        },
        "f2437c2ab4e3455d8c1e1f73f19fb194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61e0a781fff14cc5b67a0403f1001714",
            "placeholder": "​",
            "style": "IPY_MODEL_af9b96e90f89417fba59592c2ee9205e",
            "value": "Running Inference: 100%"
          }
        },
        "7a913ac6684a4275a1a45e8a8e593f35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67bc247b05a44b1d91ab90f021e97112",
            "max": 142,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4eb37ae6534446b1b24d96b3f7368cbc",
            "value": 142
          }
        },
        "0437ca2134404edfa5a8fe7acac74626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1112157e81534fc8ab777b22c51c1446",
            "placeholder": "​",
            "style": "IPY_MODEL_f746bf4c81fd44b9aeda7f920774f9bb",
            "value": " 142/142 [00:00&lt;00:00, 9557.90it/s]"
          }
        },
        "4cc18bbf4eda4a2cb14f202fe72e7bdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61e0a781fff14cc5b67a0403f1001714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9b96e90f89417fba59592c2ee9205e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67bc247b05a44b1d91ab90f021e97112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb37ae6534446b1b24d96b3f7368cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1112157e81534fc8ab777b22c51c1446": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f746bf4c81fd44b9aeda7f920774f9bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code puts together the end-to-end data pipeline to fine-tune DistilBERT, a lighter and optimized version of BERT, for question-answering tasks using my course materials. This pipeline consists of five critical phases: environment setup, data ingestion, text cleaning, GPU optimization, and dataset preparation.\n",
        "\n",
        "First, the code mounts my Google Drive using drive.mount() to reach the Excel file containing my web-scraped course data; this dataset includes structured question-answer pairs and their context passages extracted from course modules. Then, it imports necessary libraries: PyTorch for tensor operations, pandas for DataFrame manipulation, regex for pattern-based text cleaning, Hugging Face's transformers library for DistilBERT access, and the datasets library for efficient streaming of the data during training.\n",
        "\n",
        "The cleaning step then applies quite rigorous text preprocessing: HTML tag removal takes care of the artifacts from web scraping; URL elimination removes hyperlinks; whitespace normalization reduces multiple spaces to singles; special character filtering keeps just alphanumeric text and punctuation. These transformations ensure that my model trains on clean, standardized input devoid of any noise.\n",
        "\n",
        "Critically, my code uses torch.cuda.is_available() to detect whether a GPU is available; and it hugely speeds up training, roughly 5-10x faster compared to CPU training. Finally, the preprocessed data is converted into Hugging Face's Dataset format for transformer training efficiency and then split 80/20 into training and evaluation sets using train_test_split(test_size=0.2, seed=42) where the seed ensures reproducibility across runs; this is important to maintain consistent experimental baselines for when I iteratively refine my model for QA."
      ],
      "metadata": {
        "id": "LDkbIboypqOS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {
        "id": "BOQpViEWvJcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7abd29-18bc-40c6-e005-ac2034e78c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Cleaned dataset shape: (710, 7)\n",
            "Using GPU: Tesla T4\n",
            "\n",
            "--- Loading and Preprocessing Data ---\n",
            "Dataset({\n",
            "    features: ['ID', 'Title', 'Context', 'Question', 'Answer', 'Unnamed: 5', 'Unnamed: 6', '__index_level_0__'],\n",
            "    num_rows: 568\n",
            "})\n",
            "Dataset({\n",
            "    features: ['ID', 'Title', 'Context', 'Question', 'Answer', 'Unnamed: 5', 'Unnamed: 6', '__index_level_0__'],\n",
            "    num_rows: 142\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import re\n",
        "from datasets import Dataset\n",
        "from transformers import DistilBertForQuestionAnswering, DistilBertTokenizerFast\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "\n",
        "# Load your CSV\n",
        "df = pd.read_excel(\"/content/drive/My Drive/Data Collection (ITE Elective Course Lesson)/Dataset/Webscraped data_Modules_Question and Answering.xlsx\")\n",
        "\n",
        "\n",
        "# Text Preprocessing Dataset\n",
        "\n",
        "# Drop rows with missing essential fields\n",
        "df.dropna (subset=['Title', 'Context', 'Question', 'Answer'], inplace=True)\n",
        "\n",
        "# Ensure text fields are string\n",
        "for col in ['Context', 'Question', 'Answer', 'Title']:\n",
        "  df[col] = df[col].astype(str)\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<[^>]+>', '', text)          # remove HTML tags\n",
        "    text = re.sub(r'\\s+', ' ', text)             # normalize whitespace\n",
        "    text = re.sub(r'http\\S+', '', text)          # remove URLs\n",
        "    text = re.sub(r'[^A-Za-z0-9.,;:?!\\'\"()\\-\\s]', '', text)  # keep punctuation\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "# Apply Cleaning\n",
        "df['Context'] = df['Context'].apply(clean_text)\n",
        "df['Question'] = df['Question'].apply(clean_text)\n",
        "df['Answer'] = df['Answer'].apply(clean_text)\n",
        "\n",
        "print(f\"Cleaned dataset shape: {df.shape}\")\n",
        "\n",
        "# Check GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU.\")\n",
        "\n",
        "print(\"\\n--- Loading and Preprocessing Data ---\")\n",
        "\n",
        "#  Convert pandas DataFrame to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df)\n",
        "\n",
        "#  Split into train and eval sets (e.g., 80% / 20%)\n",
        "dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
        "train_data = dataset[\"train\"]\n",
        "eval_data = dataset[\"test\"]\n",
        "\n",
        "print(train_data)\n",
        "print(eval_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bert-base-uncased**"
      ],
      "metadata": {
        "id": "aJIx9GC8IbTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code prepares my dataset for BERT-based question-answering by performing three necessary transformations: loading pre-trained BERT components, mapping answer text positions to token indices, and tokenizing question-context pairs with precise alignment tracking. First, it loads the bert-base-uncased tokenizer and model from Hugging Face onto which my fine-tuning is based.\n",
        "\n",
        "The add_answer_positions() function does some critical preprocessing in finding where exactly the answer text falls within its corresponding context passage. With case-insensitive matching, context.lower().find(answer_lower), it calculates positions at character level, which is vital since BERT operates on token-level predictions and not on the raw text. When there are no substrings of answers—handling for edge cases—default positions avoid crashes.\n",
        "\n",
        "Then, tokenize_and_align() does the most complicated work of all: converting my text into BERT's 512-token vocabulary while maintaining the answer position mapping. The tokenizer uses truncation=\"only_second\" for question preservation, and return_offsets_mapping=True to track which tokens correspond to which characters. Using these offset mappings and sequence IDs which distinguish question tokens (ID 0) from context tokens (ID 1), we're going to map my character-level answer positions into token-level positions.\n",
        "\n",
        "Finally, this code applies these transformations via `.map()` to both training and evaluation datasets, converts outputs to PyTorch tensors with `.set_format(\"torch\", .)`, and loads the model onto the GPU device for efficient training. This ensures that BERT receives correctly aligned token-span targets during fine-tuning and that answer span prediction is accurate."
      ],
      "metadata": {
        "id": "uIePC-FzOToF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
        "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(f\"\\n🧠 Loaded Pretrained QnA Model: {MODEL_NAME}\")\n",
        "\n",
        "\n",
        "def add_answer_positions(example):\n",
        "    context = example[\"Context\"]\n",
        "    answer = example[\"Answer\"]\n",
        "\n",
        "    # Lowercase-safe matching\n",
        "    context_lower = context.lower()\n",
        "    answer_lower = answer.lower()\n",
        "\n",
        "    answer_start = context_lower.find(answer_lower)\n",
        "    if answer_start == -1:\n",
        "        # If not found, set defaults\n",
        "        example[\"start_positions\"] = 0\n",
        "        example[\"end_positions\"] = 0\n",
        "    else:\n",
        "        answer_end = answer_start + len(answer)\n",
        "        example[\"start_positions\"] = answer_start\n",
        "        example[\"end_positions\"] = answer_end\n",
        "\n",
        "    return example\n",
        "\n",
        "\n",
        "def tokenize_and_align(examples):\n",
        "    tokenized = tokenizer(\n",
        "        examples[\"Question\"],\n",
        "        examples[\"Context\"],\n",
        "        truncation=\"only_second\",  # focus on context truncation only\n",
        "        padding=\"max_length\",\n",
        "        max_length=512,\n",
        "        return_offsets_mapping=True\n",
        "    )\n",
        "\n",
        "    start_positions = []\n",
        "    end_positions = []\n",
        "\n",
        "    for i, offsets in enumerate(tokenized[\"offset_mapping\"]):\n",
        "        sequence_ids = tokenized.sequence_ids(i)\n",
        "        context_start = sequence_ids.index(1)\n",
        "        context_end = len(sequence_ids) - 1 - sequence_ids[::-1].index(1)\n",
        "\n",
        "        start_char = examples[\"start_positions\"][i]\n",
        "        end_char = examples[\"end_positions\"][i]\n",
        "\n",
        "        # Initialize defaults\n",
        "        token_start_index = context_start\n",
        "        token_end_index = context_start\n",
        "\n",
        "        # Map char → token span\n",
        "        for idx in range(context_start, context_end + 1):\n",
        "            if offsets[idx][0] <= start_char < offsets[idx][1]:\n",
        "                token_start_index = idx\n",
        "            if offsets[idx][0] < end_char <= offsets[idx][1]:\n",
        "                token_end_index = idx\n",
        "                break\n",
        "\n",
        "        start_positions.append(token_start_index)\n",
        "        end_positions.append(token_end_index)\n",
        "\n",
        "    tokenized[\"start_positions\"] = start_positions\n",
        "    tokenized[\"end_positions\"] = end_positions\n",
        "    tokenized.pop(\"offset_mapping\")  # cleanup\n",
        "\n",
        "    return tokenized\n",
        "\n",
        "\n",
        "# Apply add_answer_positions to train and eval data\n",
        "train_data = train_data.map(add_answer_positions)\n",
        "eval_data = eval_data.map(add_answer_positions)\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_train = train_data.map(tokenize_and_align, batched=True)\n",
        "tokenized_eval = eval_data.map(tokenize_and_align, batched=True)\n",
        "\n",
        "tokenized_train.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
        "tokenized_eval.set_format(\"torch\", columns=['input_ids', 'attention_mask', 'start_positions', 'end_positions'])\n",
        "\n",
        "\n",
        "# === Load Model ===\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME).to(device)\n",
        "\n",
        "print(f\"\\n🧩 Model loaded successfully for QnA: {MODEL_NAME}\")"
      ],
      "metadata": {
        "id": "lkp9RR_6yOSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "c476fdb38d174937888fe6c398eb6387",
            "fc5ba260884b45bc8dcfdf6a9b0da7a2",
            "a657d760f37f4a3c90e6ec7fd8ef6535",
            "ac160a5790794692a21ad2241bd6a277",
            "6d91b7577b2b4cd5806e1203ed140b2f",
            "8fc8c35ad95b4c44a53f27c349c6e39e",
            "aa7c967464874097bea69b21419bb64c",
            "2ac6a96ceae04010aadb43a549478b60",
            "144b46aad4784fd0963e49c147ca9362",
            "684a02e2696148d5a03b729c50344140",
            "ddd7e12993404ee59696b193e9e151be",
            "050497efd49d47df81703adeb97fe9ab",
            "c36f94904cbc408dad215dce1061e3e6",
            "67f12e28219a4169b5bba9df768a7529",
            "c8ac9e5f950241119853e382246b4e5d",
            "b424fcd4870248ed9208b612f598ae26",
            "e0421c0457724f898a138b3a9fac4361",
            "2be2d021b19446dbb754f6543f07ae4f",
            "ecac224058354346a8775d1e2ae7d452",
            "ff9c8bb07b4347e0ad691814874f2de1",
            "ea39cec509fe4cfab50ca77e45a6de14",
            "63f791be91a1405d8abea3855570f738",
            "69668b0e7f984367a2e940a390130324",
            "193fa850bf64455e97629dd4fbda9c87",
            "47c286eabf8f4e80a0ff2e95248e8395",
            "a0a74fdfba184c4ea377e1462dad5b93",
            "dce349668ceb4f6391c6ee41678d0c94",
            "e8e7589ffa72435ea3dd13e9368c7afe",
            "68840400ca6c4bc89a2ee9cf874b8bb5",
            "1f585c1b27534a7daa5cdc24c7e721e8",
            "c2480293a1114453a6f279fd71d30a78",
            "3fadb950901345b7ae8c977743ab00a3",
            "9360e28880b047058a0497da5c720be5",
            "143e42839a08430eb23613f520d4c201",
            "fd2072c854214edbb3698ef30f95c021",
            "d458a4e7230140e59f596fb7587c2d07",
            "22c8cc9d114c414a971fd1e55e65a0f5",
            "e370c67ac0c940468477e928c77b98ff",
            "a5c963838a8b4cb0b0e53f05189cfae0",
            "38a1b0e400d044cd81c5227f79042a44",
            "c7f9da76a46941d4b5173adf408822ed",
            "60c6327a29474260a08c4d7372b95542",
            "eb99c9ccf3324629afa0dad021d35618",
            "bd4666b68fee425f857196b254b51d62"
          ]
        },
        "outputId": "ea8bbba9-0792-4301-9dc0-12015954ce91"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧠 Loaded Pretrained QnA Model: bert-base-uncased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c476fdb38d174937888fe6c398eb6387"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/142 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "050497efd49d47df81703adeb97fe9ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69668b0e7f984367a2e940a390130324"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/142 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "143e42839a08430eb23613f520d4c201"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧩 Model loaded successfully for QnA: bert-base-uncased\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "orJ1vJMTKVzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **METRICS AND TRAINING SETUP**"
      ],
      "metadata": {
        "id": "PnJYq08SJOfw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a comprehensive evaluation framework and training pipeline for fine-tuning my BERT question-answering model. The section establishes two custom metrics—Exact Match (EM) and F1 Score—that measure answer prediction quality by comparing predicted answer text against ground-truth answers. These metrics operate at the character/token level, not just raw logit predictions, providing intuitive performance indicators.\n",
        "The compute_metrics() function runs the entire evaluation workflow: it receives model predictions of start and end logits, converts raw logits to token indices via np.argmax(), reconstructs predicted answer text by decoding the token span, and compares this text against the gold-standard answer using both EM and F1 calculations. The function also tracks average inference time for operational performance insights. Importantly, this function bridges the gap from BERT's token-level outputs to human-readable text comparisons that enable meaningful model assessment.\n",
        "The configuration of training via TrainingArguments defines several hyperparameters responsible for fine-tuning: 3 epochs, batch sizes reduced to 16 to manage GPU memory, learning rate was set to 0.005, and weight decay of 0.01 for regularization. We set eval_strategy=\"no\" because a full evaluation may be time-consuming, but epocs and steps can be applied for experimentation. We also set fp16=True in order to perform mixed-precision training. Finally, the object responsible for performing the complete training loop is the Trainer. It bundles model, datasets, metrics, and tokenizer and handles for us both training iterations (with gradient update) and the different evaluation cycles.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "07nZsnViP47q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. METRICS AND TRAINING SETUP ---\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers.data.data_collator import default_data_collator # Import default_data_collator\n",
        "\n",
        "def compute_exact_match(prediction, truth):\n",
        "    return int(prediction.strip().lower() == truth.strip().lower())\n",
        "\n",
        "def compute_f1(prediction, truth):\n",
        "    pred_tokens = prediction.lower().split()\n",
        "    truth_tokens = truth.lower().split()\n",
        "\n",
        "    common = set(pred_tokens) & set(truth_tokens)\n",
        "    if not common:\n",
        "        return 0.0\n",
        "\n",
        "    precision = len(common) / len(pred_tokens)\n",
        "    recall = len(common) / len(truth_tokens)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    start_time = time.time()\n",
        "\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # DistilBERT QA produces start and end logits\n",
        "    start_logits, end_logits = predictions\n",
        "\n",
        "    # Take the highest scoring token for start and end\n",
        "    start_positions = np.argmax(start_logits, axis=1)\n",
        "    end_positions = np.argmax(end_logits, axis=1)\n",
        "\n",
        "    exact_matches = []\n",
        "    f1_scores = []\n",
        "\n",
        "    # Tokenizer needed to decode back to text\n",
        "    for i in range(len(start_positions)):\n",
        "        input_ids = tokenized_eval[i][\"input_ids\"]\n",
        "        pred_tokens = input_ids[start_positions[i]: end_positions[i] + 1]\n",
        "        pred_text = tokenizer.decode(pred_tokens, skip_special_tokens=True)\n",
        "\n",
        "        # Ground-truth answer text\n",
        "        gold_text = eval_data[i][\"Answer\"]\n",
        "\n",
        "        exact_matches.append(compute_exact_match(pred_text, gold_text))\n",
        "        f1_scores.append(compute_f1(pred_text, gold_text))\n",
        "\n",
        "    # Average inference time\n",
        "    avg_inference_time = (time.time() - start_time) / len(start_positions)\n",
        "\n",
        "    metrics = {\n",
        "        \"Exact_Match\": np.mean(exact_matches),\n",
        "        \"F1_Score\": np.mean(f1_scores),\n",
        "        \"Avg_Inference_Time\": avg_inference_time\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Define training arguments (hyperparameters)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16, # Reduced batch size\n",
        "    per_device_eval_batch_size=16, # Reduced batch size\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    learning_rate=0.005,\n",
        "    logging_steps=100,\n",
        "    eval_strategy=\"no\",\n",
        "    save_strategy=\"no\",\n",
        "    load_best_model_at_end=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=[]\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer, # Keep tokenizer for data collation\n",
        "    data_collator=default_data_collator, # Use default data collator\n",
        ")"
      ],
      "metadata": {
        "id": "eJPYKdMNz2r8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48c19b7-b30f-4c80-9c80-8c4c6f3788ab"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1961544106.py:109: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Execution (Evaluation)**"
      ],
      "metadata": {
        "id": "dWy6J1HBJVYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluatiion. This code orchestrates the complete training phase of fine-tuning my BERT question-answering model, including training initiation, performance evaluation, and model persistence. It first shows comprehensive pre-training diagnostics: the model name, the number of epochs, the batch size, and whether it is using a GPU/CPU device. The actual execution has been done by calling trainer.train(), which handles the whole training loop across 3 epochs, computing gradients, updating weights, and logging without explicit developer intervention. Tracking the duration of training provides operational insights: the time elapsed since the start until its completion will tell if hardware acceleration-GPU-is reducing computation time.\n",
        "After successful training, the code does final evaluation on the held-out test set using trainer.evaluate(), which applies my custom metrics functions, Exact Match and F1 Score, in order to measure generalization performance on unseen data. Results are displayed with formatted precision (4 decimal places) for readability. Importantly, this final evaluation reveals the true model performance: training metrics can be very misleading due to overfitting, and testing on withheld data makes that assessment the most honest.\n",
        "The final step saves the fine-tuned model along with the tokenizer via trainer.save_model(); this will create a reusable checkpoint for later inference. The directory creation with os.makedirs(., exist_ok=True) addresses cases where the save path does not exist. This saved model now serves as a deliverable for production deployment or further downstream analysis, hence turning this fine-tuning effort into an asset. Status messages across the workflow provide feedback to the user and transform what was otherwise a black-box process into a clear and monitorable pipeline.\n",
        "\n"
      ],
      "metadata": {
        "id": "cvR6hHMGQrLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "\n",
        "# --- 5. EXECUTION: START THE FINE-TUNING PROCESS ---\n",
        "\n",
        "print(\"🚀\" + \"=\"*50)\n",
        "print(\"              STARTING MODEL FINE-TUNING\")\n",
        "print(\"=\"*50 + \"🚀\")\n",
        "print(f\"Model: {MODEL_NAME}\")\n",
        "print(f\"Number of Training Epochs: {training_args.num_train_epochs}\")\n",
        "print(f\"Training Batch Size: {training_args.per_device_train_batch_size}\")\n",
        "print(f\"Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "print(\"-\" * 54)\n",
        "\n",
        "training_start_time = time.time()\n",
        "\n",
        "print(\"\\n[INFO] Training in progress... Please wait.\\n\")\n",
        "trainer.train()\n",
        "\n",
        "# Calculate and display the total training time\n",
        "training_end_time = time.time()\n",
        "training_duration = training_end_time - training_start_time\n",
        "print(f\"\\n[SUCCESS] Fine-tuning completed in {training_duration / 60:.2f} minutes.\")\n",
        "\n",
        "\n",
        "# --- 6. FINAL EVALUATION ON THE TEST SET ---\n",
        "\n",
        "print(\"\\n\\n✅\" + \"=\"*50)\n",
        "print(\"              PERFORMING FINAL EVALUATION\")\n",
        "print(\"=\"*50 + \"✅\")\n",
        "print(\"Evaluating the best model checkpoint on the hold-out test set...\")\n",
        "\n",
        "final_eval_results = trainer.evaluate()\n",
        "\n",
        "# Print the results in a more readable format\n",
        "print(\"\\n--- Final Evaluation Metrics ---\")\n",
        "for key, value in final_eval_results.items():\n",
        "    # Format floating point numbers for better readability\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key:<25}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"{key:<25}: {value}\")\n",
        "print(\"-\" * 34)\n",
        "\n",
        "\n",
        "# --- 7. SAVING THE FINE-TUNED MODEL ---\n",
        "\n",
        "print(\"\\n\\n💾\" + \"=\"*50)\n",
        "print(\"                 SAVING THE FINAL MODEL\")\n",
        "print(\"=\"*50 + \"💾\")\n",
        "\n",
        "# Define a path to save the model and tokenizer\n",
        "final_model_path = \"./fine-tuned-bert-qna-model\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(final_model_path, exist_ok=True)\n",
        "\n",
        "# The save_model() method saves everything needed to reuse the model:\n",
        "# - The model weights (pytorch_model.bin)\n",
        "# - The model configuration (config.json)\n",
        "# - The tokenizer files (vocab.txt, tokenizer_config.json, etc.)\n",
        "trainer.save_model(final_model_path)\n",
        "\n",
        "print(f\"\\n[SUCCESS] Model and tokenizer have been saved to: '{final_model_path}'\")\n",
        "print(\"\\nThis model can now be loaded for inference in the 'Actual Testing' stage.\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"                PROCESS COMPLETE\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "id": "aPpb02yu0_l8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "outputId": "fc6250c5-f56c-4dbf-d3d0-9e31a5630bb1"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀==================================================\n",
            "              STARTING MODEL FINE-TUNING\n",
            "==================================================🚀\n",
            "Model: bert-base-uncased\n",
            "Number of Training Epochs: 3\n",
            "Training Batch Size: 16\n",
            "Device: GPU\n",
            "------------------------------------------------------\n",
            "\n",
            "[INFO] Training in progress... Please wait.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [108/108 00:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.892600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[SUCCESS] Fine-tuning completed in 0.71 minutes.\n",
            "\n",
            "\n",
            "✅==================================================\n",
            "              PERFORMING FINAL EVALUATION\n",
            "==================================================✅\n",
            "Evaluating the best model checkpoint on the hold-out test set...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [9/9 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Final Evaluation Metrics ---\n",
            "eval_loss                : 6.2383\n",
            "eval_Exact_Match         : 0.0000\n",
            "eval_F1_Score            : 0.0000\n",
            "eval_Avg_Inference_Time  : 0.0010\n",
            "eval_runtime             : 1.1433\n",
            "eval_samples_per_second  : 124.2020\n",
            "eval_steps_per_second    : 7.8720\n",
            "epoch                    : 3.0000\n",
            "----------------------------------\n",
            "\n",
            "\n",
            "💾==================================================\n",
            "                 SAVING THE FINAL MODEL\n",
            "==================================================💾\n",
            "\n",
            "[SUCCESS] Model and tokenizer have been saved to: './fine-tuned-bert-qna-model'\n",
            "\n",
            "This model can now be loaded for inference in the 'Actual Testing' stage.\n",
            "\n",
            "============================================================\n",
            "                PROCESS COMPLETE\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actual Testing**"
      ],
      "metadata": {
        "id": "QWTDiCCgJZVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lastly, code executes an end-to-end inference pipeline to deploy the fine-tuned BERT model on unseen question-answering data, transforming raw text into predicted answers with confidence scores. This pipeline is implemented using Hugging Face's high-level API, pipeline(), abstracting away tokenization, model inference, and post-processing—reducing deployment to just a few function calls from dozens. The workflow begins with the initialization of the QnA pipeline, configured to run on a GPU device=0 if available or CPU device=-1 by default, thus guaranteeing hardware-optimal execution irrespective of the environment in which it is executed.\n",
        "Data preparation converts the held-out evaluation dataset from Hugging Face format to pandas DataFrame, then rearranges it into a list of dictionaries with question-context pairs-the format expected by the pipeline. This batch-oriented approach hugely boosts inference speed compared to sequential prediction loops. The actual inference step processes all samples simultaneously through qna_pipeline() with batch_size=16, which groups examples for GPU parallelization. The tqdm progress bar shows visual feedback during the potentially time-intensive inference that is critical for transparency when dealing with hundreds or thousands of examples.\n",
        "Finally, predictions extract answer text and confidence scores from pipeline outputs, append these as new DataFrame columns, and show results next to ground-truth answers for validation. An optional export to CSV writes the predictions to Google Drive so that they can be used for further analysis or shared with stakeholders. This complete workflow shows how production-grade inference differs from training: simpler, optimized for throughput, and instrumented with monitoring features that turn a black-box model into an interpretable system.\n",
        "\n"
      ],
      "metadata": {
        "id": "f5wYjE-ZRQ7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm.auto import tqdm # Import tqdm for the progress bar\n",
        "\n",
        "# Assuming 'model' and 'tokenizer' are already loaded from the training phase\n",
        "# and 'df' is your original DataFrame.\n",
        "\n",
        "# --- 1. Initialize the QnA Pipeline ---\n",
        "# This is the same as your original code.\n",
        "qna_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1\n",
        ")\n",
        "print(\"✅ QnA Pipeline Initialized on GPU.\" if torch.cuda.is_available() else \"QnA Pipeline Initialized on CPU.\")\n",
        "\n",
        "\n",
        "# --- 2. Prepare Data for Batch Inference ---\n",
        "# Instead of a loop, we create a list of dictionaries. This is much faster.\n",
        "# We'll use the 'eval_data' set created during splitting to test the model's performance on unseen data.\n",
        "# If you want to run on the whole dataset, just use the original 'df'.\n",
        "\n",
        "# Let's use the evaluation dataset for a fair test\n",
        "test_df = eval_data.to_pandas() # Convert the Hugging Face dataset back to a pandas DataFrame\n",
        "\n",
        "# Create a list of dictionaries in the format the pipeline expects\n",
        "inference_samples = []\n",
        "for _, row in test_df.iterrows():\n",
        "    inference_samples.append({\n",
        "        \"question\": row[\"Question\"],\n",
        "        \"context\": row[\"Context\"]\n",
        "    })\n",
        "\n",
        "print(f\"\\n🚀 Prepared {len(inference_samples)} samples for inference.\")\n",
        "\n",
        "\n",
        "# --- 3. Run Batch Inference with a Progress Bar ---\n",
        "# The pipeline processes the entire list at once. We wrap it with tqdm for a progress bar.\n",
        "# You can adjust the 'batch_size' for performance tuning.\n",
        "predictions = []\n",
        "for result in tqdm(qna_pipeline(inference_samples, batch_size=16), total=len(inference_samples), desc=\"Running Inference\"):\n",
        "    predictions.append(result)\n",
        "\n",
        "\n",
        "# --- 4. Process and Display Results ---\n",
        "# Extract just the predicted answers and scores\n",
        "predicted_answers = [p['answer'] for p in predictions]\n",
        "scores = [p['score'] for p in predictions]\n",
        "\n",
        "# Add the predictions and scores as new columns to our test DataFrame\n",
        "test_df['predicted_answer'] = predicted_answers\n",
        "test_df['confidence_score'] = scores\n",
        "\n",
        "# Display the results for review. The 'display()' function provides better formatting in notebooks.\n",
        "print(\"\\n✅ Inference Complete! Here are the results:\")\n",
        "display(test_df[['Question', 'Answer', 'predicted_answer', 'confidence_score']].head())\n",
        "\n",
        "\n",
        "# --- 5. (Optional) Save the Results to a CSV ---\n",
        "output_file = \"/content/drive/My Drive/qna_predictions.csv\"\n",
        "test_df.to_csv(output_file, index=False)\n",
        "print(f\"\\n💾 Results saved to {output_file}\")"
      ],
      "metadata": {
        "id": "SCFl34Gv5NV-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431,
          "referenced_widgets": [
            "551fb5ab03dc4fec9c78399eb4c8ef0c",
            "f2437c2ab4e3455d8c1e1f73f19fb194",
            "7a913ac6684a4275a1a45e8a8e593f35",
            "0437ca2134404edfa5a8fe7acac74626",
            "4cc18bbf4eda4a2cb14f202fe72e7bdf",
            "61e0a781fff14cc5b67a0403f1001714",
            "af9b96e90f89417fba59592c2ee9205e",
            "67bc247b05a44b1d91ab90f021e97112",
            "4eb37ae6534446b1b24d96b3f7368cbc",
            "1112157e81534fc8ab777b22c51c1446",
            "f746bf4c81fd44b9aeda7f920774f9bb"
          ]
        },
        "outputId": "3f8d1366-7f14-4914-cdfd-62a33c897e2f"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ QnA Pipeline Initialized on GPU.\n",
            "\n",
            "🚀 Prepared 142 samples for inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/pipelines/question_answering.py:395: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running Inference:   0%|          | 0/142 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "551fb5ab03dc4fec9c78399eb4c8ef0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Inference Complete! Here are the results:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            Question  \\\n",
              "0  How is sentiment analysis applied in customer ...   \n",
              "1  What type of prediction problem does the logis...   \n",
              "2  What are the two primary strategies for solvin...   \n",
              "3  What are the three fundamental components that...   \n",
              "4  What exhaustive approach characterizes grid se...   \n",
              "\n",
              "                                              Answer  \\\n",
              "0  In customer service, it analyzes reviews to un...   \n",
              "1  The logistic regression model determines wheth...   \n",
              "2  Multi-class classification can be approached b...   \n",
              "3  The three components are the encoder, the cont...   \n",
              "4  Grid search uses brute force by assembling all...   \n",
              "\n",
              "                                    predicted_answer  confidence_score  \n",
              "0    PRACTICAL APPLICATIONS OF SENTIMENT ANALYSIS 1.          0.000076  \n",
              "1  A slightly more complex example might be using...          0.001633  \n",
              "2         Multi-class classification problems can be          0.000164  \n",
              "3                 Literature widely presents encoder          0.002081  \n",
              "4                Grid search is a brute force method          0.000331  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e76389dd-6f84-4e6a-98bf-ea3ee4d999f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>predicted_answer</th>\n",
              "      <th>confidence_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How is sentiment analysis applied in customer ...</td>\n",
              "      <td>In customer service, it analyzes reviews to un...</td>\n",
              "      <td>PRACTICAL APPLICATIONS OF SENTIMENT ANALYSIS 1.</td>\n",
              "      <td>0.000076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What type of prediction problem does the logis...</td>\n",
              "      <td>The logistic regression model determines wheth...</td>\n",
              "      <td>A slightly more complex example might be using...</td>\n",
              "      <td>0.001633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What are the two primary strategies for solvin...</td>\n",
              "      <td>Multi-class classification can be approached b...</td>\n",
              "      <td>Multi-class classification problems can be</td>\n",
              "      <td>0.000164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the three fundamental components that...</td>\n",
              "      <td>The three components are the encoder, the cont...</td>\n",
              "      <td>Literature widely presents encoder</td>\n",
              "      <td>0.002081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What exhaustive approach characterizes grid se...</td>\n",
              "      <td>Grid search uses brute force by assembling all...</td>\n",
              "      <td>Grid search is a brute force method</td>\n",
              "      <td>0.000331</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e76389dd-6f84-4e6a-98bf-ea3ee4d999f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e76389dd-6f84-4e6a-98bf-ea3ee4d999f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e76389dd-6f84-4e6a-98bf-ea3ee4d999f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7dbf5e7c-ec2c-44ab-8123-ee0651817064\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dbf5e7c-ec2c-44ab-8123-ee0651817064')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7dbf5e7c-ec2c-44ab-8123-ee0651817064 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(f\\\"\\\\n\\ud83d\\udcbe Results saved to {output_file}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What type of prediction problem does the logistic regression example address, and what is the input variable used for making this prediction?\",\n          \"What exhaustive approach characterizes grid search for learning rate determination, how does it systematically test potential values, and what role does validation play in refining hyperparameters?\",\n          \"What are the two primary strategies for solving multi-class classification problems, and which specific technique do neural networks typically use to implement the probability-based approach?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The logistic regression model determines whether or not a house will sell based on how many days the home is on the market.\",\n          \"Grid search uses brute force by assembling all potential learning rates, testing each one, and using validation on new data to update hyperparameters.\",\n          \"Multi-class classification can be approached by computing the relative probability of a data point belonging to each category and selecting the highest probability, typically employed by neural networks using a softmax activation function, or by dividing the problem into a series of binary classification problems.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A slightly more complex example might be using a logistic\",\n          \"Grid search is a brute force method\",\n          \"Multi-class classification problems can be\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.000931080547932885,\n        \"min\": 7.561435631942004e-05,\n        \"max\": 0.002081165323033929,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0016326530603691936,\n          0.0003305784775875509,\n          0.00016436555597465485\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Results saved to /content/drive/My Drive/qna_predictions.csv\n"
          ]
        }
      ]
    }
  ]
}